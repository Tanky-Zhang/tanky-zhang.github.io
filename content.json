{"meta":{"title":"tanky","subtitle":"软件开发的小学生","description":"","author":"TankyZhang","url":"http://yoursite.com"},"pages":[{"title":"search","date":"2020-08-17T12:46:32.000Z","updated":"2020-08-17T12:47:36.598Z","comments":false,"path":"search/index.html","permalink":"http://yoursite.com/search/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-08-16T14:08:36.000Z","updated":"2020-08-16T14:09:01.141Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2020-07-05T07:59:28.000Z","updated":"2020-09-24T05:38:36.307Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"Volatile详解","slug":"Volatile详解","date":"2020-10-21T00:48:39.497Z","updated":"2020-10-21T08:48:59.042Z","comments":true,"path":"2020/10/21/Volatile详解/","link":"","permalink":"http://yoursite.com/2020/10/21/Volatile%E8%AF%A6%E8%A7%A3/","excerpt":"","text":"Volatile详解一、Intel硬件提供了一系列的内存屏障： lfence，是一种Load Barrier 读屏障 sfence, 是一种Store Barrier 写屏障 mfence, 是一种全能型的屏障，具备ifence和sfence的能力 Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。它后面可以跟ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG等指令。 《Java虚拟机规范》[1]中曾试图定义一种“Java内存模型”[2]（Java Memory Model，JMM）来屏 蔽各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效 果。在此之前，主流程序语言（如C和C++等）直接使用物理硬件和操作系统的内存模型。因此，由于 不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正常，而在另外一套平台上并发 访问却经常出错，所以在某些场景下必须针对不同的平台来编写程序。 二、Votile保证了有序性、可见性1.为什么会发生不可见这种情况​ 那要从计算机硬件讲起，现代计算机cpu和内存之间都会存在着缓存，一般分为L1，L2，L3三级缓存，设计成这个样子主要是因为CPU的运行速度较快，但是内存的运行速度是远低于CPU的，所以为了减小这种速度的差距提高小效率就设计了三级缓存的概念。如图： 1 因为这样的结构就导致了如果某个cpu从内存中读取数据（一个缓存行大小的数据）就会缓存到高速缓存中，如果cpu的两个核心同时操作了同一块数据，那么这一块数据同时会被缓存两份，一个核心操作一份，如果说某个核心对数据进行了修改，并且写回主内存，但是另外一个核心操作的还是旧的数据，这样就导致了数据的不可见。而加上了volitale就保证了可见性。这种情况下如何保证缓存数据的一致性，其实cpu采用了MESI 及其变种协议去做缓存一致性维护。我们主要来理解下什么是MESI： 状态 描述 监听任务 M 修改 (Modified) 该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。 缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。 E 独享、互斥 (Exclusive) 该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。 缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。 S 共享 (Shared) 该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。 缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。 I 无效 (Invalid) 该Cache line无效。 无 通过上边表格我们可以发现，MESI其实就是四个字母的缩写，Modified,Exclusive,Shared,Invalid这四个单词分别代表了四种状态。 这四种状态之间可以相互转换： ​ 一开始线程A将一个缓存行的数据读入Cache中，这时候的数据是Exclusive状态，数据只存在于本Cache中，同时它监听着其他缓存读取主存中该缓存行的操作，如果此时有某个线程B读取该缓存行，那么此时就将两个Cache中的缓存行置为Shared状态，此时缓存行在监听其他缓存使该缓存无效或者独享的请求，假设线程A对该缓存行的数据进行了修改，这时候总线嗅探机制嗅探到该缓存行的变化，则置线程B的缓存为Invalid无效状态，同时将线程A的缓存置为Modified状态。恰好线程B想再次读取该缓存行，那么线程B所在核心会通知线程A所在核心，将线程A修改后的数据同步到主内存，并且将所在Cache的缓存行设置为Exclusive状态。然后线程B从主存中读取数据到Cache中，同时将该缓存行设置为Shared状态。 ​ 同时为了解决切换状态时候的堵塞问题还引入了Store Bufferes来解决这个问题，但是这种缓存一致性协议并不能够解决指令重排的问题，于是引入了内存屏障这个概念，也就是我们在上边讲到的各种内存屏障的实现。这种内存屏障的实现和硬件有很大的关系，java中的内存屏障其实就是借助于上边的第四种方式来实现的，也就是使用了Lock前缀。 2.什么是缓存行（cache line）​ 刚才我们一直在提缓存行（Cache Line），到底什么是缓存行，缓存行可以理解成读取到高速缓冲区的最小单位，将数据从内存读取到缓存中的时候如果一个字节一个字节的读肯定是比较耗时的操作，所以根据程序的局部性原理就采取了按照缓存行的大小往高速缓冲区中读取，如果是64位的电脑我们的缓存行大小一般是64Bytes。 3.伪共享（flash sharing）问题​ 我们了解了缓存行，再来解析另外一个概念–伪共享，如果当两个缓存同时缓存了同一个缓存行的数据，但是呢并没有操作同一个数据，只是操作的数据都存在于同一个缓存行中，那么当线程A读取一个数据的时候，线程B修改处在缓存行中的另外一个数据，此时缓存A中的数据就要失效，并且将缓存B中的数据写回到主内存，这样频繁的往主存写重新从主存读取，会极大地消耗性能，这就是伪共享问题。一般我们在程序开发中并不会处理这种伪共享问题，但是在某些框架中会对伪共享问题进行处理，比如Disruptor在定义成员变量的时候会故意拼接无用的字节，使其成员变量不处在同一个缓存行中，以此来提高性能。同时JDK 8提供了一个 sun.misc.Contended注解，用来解决伪共享问题。 4.volatile保证可见性​ 他是通过缓存一致性协议以及内存屏障来实现的，无论是volatile 还是普通变量在读写操作本身方面完全是一样的，即读写操作都交给 Cache，Cache 通过 MESI 及其变种协议去做缓存一致性维护。这两种变量的区别就只在于 内存屏障的使用上。 class字节码层面： ​ volatile 对代码生成的字节码本身没有影响，即 Java Method 生成的字节码无论里面操作的变量是不是 volatile 声明的，生成的字节码都是一样的。volatile 在字节码层面影响的是 Class 内 Field 的 access_flags我们可以看到下边代码的 flags: ACC_VOLATILE。 123456789101112131415161718volatile int v1; descriptor: I flags: ACC_VOLATILE .....void readAndWrite(); descriptor: ()V flags: Code: stack=3, locals=3, args_size=1 0: aload_0 1: getfield #52 // Field v1:I 4: istore_1 5: aload_0 6: getfield #54 // Field v2:I 9: istore_2 10: aload_0 11: iload_1 12: iload_2 汇编源码： 123456780x0000000003fb5656: mov 0x58(%r10),%r8d0x0000000003fb565a: mov %r8d,%r11d0x0000000003fb565d: add $0x2,%r11d0x0000000003fb5661: mov %r11d,0x58(%r10)0x0000000003fb5665: add $0x4,%r8d0x0000000003fb5669: mov %r8d,0x58(%r10)0x0000000003fb566d: lock addl $0x0,(%rsp) ;*putstatic a ; - ​ 通过看class字节码和汇编源码我们发现当有了volatile修饰以后最终在汇编源码上会带上lock addl这个前缀，这也就呼应了我们开篇讲的第四种实现内存屏障的方式。 ​ 在jvm层面一共提供了四种内存屏障，它们分别是：LoadLoad，StoreStore，LoadStore，StoreLoad LoadLoad：操作序列 Load1, LoadLoad, Load2，用于保证访问 Load2 的读取操作一定不能重排到 Load1 之前。类似于前面说的 Read Barrier，需要先处理 Invalidate Queue 后再读 Load2； **StoreStore:**操作序列 Store1, StoreStore, Store2，用于保证 Store1 及其之后写出的数据一定先于 Store2 写出，即别的 CPU 一定先看到 Store1 的数据，再看到 Store2 的数据。可能会有一次 Store Buffer 的刷写，也可能通过所有写操作都放入 Store Buffer 排序来保证； LoadStore：操作序列 Load1, LoadStore, Store2，用于保证 Store2 及其之后写出的数据被其它 CPU 看到之前，Load1 读取的数据一定先读入缓存。甚至可能 Store2 的操作依赖于 Load1 的当前值。这个 Barrier 的使用场景可能和上一节讲的 Cache 架构模型很难对应，毕竟那是一个极简结构，并且只是一种具体的 Cache 架构，而 JVM 的 Barrier 要足够抽象去应付各种不同的 Cache 架构。如果跳出上一节的 Cache 架构来说，我理解用到这个 Barrier 的场景可能是说某种 CPU 在写 Store2 的时候，认为刷写 Store2 到内存，将其它 CPU 上 Store2 所在 Cache Line 设置为无效的速度要快于从内存读取 Load1，所以做了这种重排。 **StoreLoad:**操作序列 Store1, StoreLoad, Load2，用于保证 Store1 写出的数据被其它 CPU 看到后才能读取 Load2 的数据到缓存。如果 Store1 和 Load2 操作的是同一个地址，StoreLoad Barrier 需要保证 Load2 不能读 Store Buffer 内的数据，得是从内存上拉取到的某个别的 CPU 修改过的值。StoreLoad一般会认为是最重的 Barrier 也是能实现其它所有 Barrier 功能的 Barrier。 但是这四种内存屏障在jvm层面中都没有借助操作系统的内存屏障，而是借住了总线锁或者是缓存锁来实现了内存屏障的功能。并且在 x86 下除了 StoreLoad之外其它 Barrier 都是空操作。volatile并不是仅仅加入内存屏障这么简单，加入内存屏障只是volatile内核指令级别的内存语义，除此之外：volatile还可以禁止编译器的指令重排，因为JVM为了优化性能并且不违反happens-before原则的前提下也会进行指令重排。禁止编译器指令重排如下： /* The “volatile” is due to gcc bugs */#define barrier() asm volatile(“”: : :”memory”) volatile的内存屏障策略非常严格保守： 在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障; 总线锁 对于早期的CPU，总是采用的是锁总线的方式。具体方法是，一旦遇到了Lock指令，就由仲裁器选择一个核心独占总线。其余的CPU核心不能再通过总线与内存通讯。从而达到“原子性”的目的。具体做法是，某一个核心触发总线的“Lock#”那根线，让总线仲裁器工作，把总线完全分给某个核心。 缓存锁 如果访问的内存区域已经缓存在处理器的缓存行中，P6系统和之后系列的处理器则不会声明LOCK#信号，它会对CPU的缓存中的缓存行进行锁定，在锁定期间，其它 CPU 不能同时缓存此数据，在修改之后，通过缓存一致性协议来保证修改的原子性，这个操作被称为缓存锁。 锁的选择 如果是P6后的CPU，并且数据已经被CPU缓存了，并且是要写回到主存的，则可以用cache locking处理问题。否则还是得锁总线。因此，lock到底用锁总线，还是用cache locking，完全是看当时的情况。当然能用后者的就肯定用后者。 Intel P6是Intel第6代架构的CPU，其实也很老了，差不多1995年出的…… 比如Pentium Pro，Pentium II，Pentium III都隶属于P6架构“ 总之，加上了volatile以后再CPU底层并没有采用系统的内存屏障，而是借用了总线锁或者是缓存锁来实现了内存屏障的功能。以此volatile保证了可见性。同时因为屏障的存在禁止了cpu的指令重排，也因此实现了有序性这个特性。 参考资料 https://www.zhihu.com/question/65372648 https://www.cnblogs.com/yanlong300/p/8986041.html https://blog.csdn.net/breakout_alex/article/details/94379895 https://segmentfault.com/a/1190000014315651 https://juejin.im/post/6844904144273145863 https://blog.csdn.net/wll1228/article/details/107775976 windows下查看汇编指令： https://blog.csdn.net/xiaomojun/article/details/94654616","categories":[],"tags":[]},{"title":"多线程","slug":"多线程","date":"2020-10-20T00:46:01.636Z","updated":"2020-10-20T00:43:26.476Z","comments":true,"path":"2020/10/20/多线程/","link":"","permalink":"http://yoursite.com/2020/10/20/%E5%A4%9A%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"CASCompare And Swap (Compare And Exchange) / 自旋 / 自旋锁 / 无锁 因为经常配合循环操作，直到完成为止，所以泛指一类操作 cas(v, a, b) ，变量v，期待值a, 修改值b ABA问题，你的女朋友在离开你的这段儿时间经历了别的人，自旋就是你空转等待，一直等到她接纳你为止 解决办法（版本号 AtomicStampedReference），基础类型简单值不需要版本号 UnsafeAtomicInteger: 123456789101112public final int incrementAndGet() &#123; for (;;) &#123; int current = get(); int next = current + 1; if (compareAndSet(current, next)) return next; &#125; &#125;public final boolean compareAndSet(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, valueOffset, expect, update); &#125; Unsafe: 1public final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5); 运用： 12345678910111213141516171819202122232425262728package com.mashibing.jol;import sun.misc.Unsafe;import java.lang.reflect.Field;public class T02_TestUnsafe &#123; int i = 0; private static T02_TestUnsafe t = new T02_TestUnsafe(); public static void main(String[] args) throws Exception &#123; //Unsafe unsafe = Unsafe.getUnsafe(); Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); Field f = T02_TestUnsafe.class.getDeclaredField(\"i\"); long offset = unsafe.objectFieldOffset(f); System.out.println(offset); boolean success = unsafe.compareAndSwapInt(t, offset, 0, 1); System.out.println(success); System.out.println(t.i); //unsafe.compareAndSwapInt() &#125;&#125; jdk8u: unsafe.cpp: cmpxchg = compare and exchange 123456UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) UnsafeWrapper(\"Unsafe_CompareAndSwapInt\"); oop p = JNIHandles::resolve(obj); jint* addr = (jint *) index_oop_from_field_offset_long(p, offset); return (jint)(Atomic::cmpxchg(x, addr, e)) == e;UNSAFE_END jdk8u: atomic_linux_x86.inline.hpp is_MP = Multi Processor 12345678inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; int mp = os::is_MP(); __asm__ volatile (LOCK_IF_MP(%4) \"cmpxchgl %1,(%3)\" : \"=a\" (exchange_value) : \"r\" (exchange_value), \"a\" (compare_value), \"r\" (dest), \"r\" (mp) : \"cc\", \"memory\"); return exchange_value;&#125; jdk8u: os.hpp is_MP() 12345678910static inline bool is_MP() &#123; // During bootstrap if _processor_count is not yet initialized // we claim to be MP as that is safest. If any platform has a // stub generator that might be triggered in this phase and for // which being declared MP when in fact not, is a problem - then // the bootstrap routine for the stub generator needs to check // the processor count directly and leave the bootstrap routine // in place until called after initialization has ocurred. return (_processor_count != 1) || AssumeMP;&#125; jdk8u: atomic_linux_x86.inline.hpp 1#define LOCK_IF_MP(mp) \"cmp $0, \" #mp \"; je 1f; lock; 1: \" 最终实现： cmpxchg = cas修改变量值 1lock cmpxchg 指令 硬件： lock指令在执行后面指令的时候锁定一个北桥信号 （不采用锁总线的方式） markword工具：JOL = Java Object Layout12345678&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.openjdk.jol/jol-core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; jdk8u: markOop.hpp 1234567891011121314151617181920// Bit-format of an object header (most significant first, big endian layout below)://// 32 bits:// --------// hash:25 ------------&gt;| age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:23 epoch:2 age:4 biased_lock:1 lock:2 (biased object)// size:32 ------------------------------------------&gt;| (CMS free block)// PromotedObject*:29 ----------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)//// 64 bits:// --------// unused:25 hash:31 --&gt;| unused:1 age:4 biased_lock:1 lock:2 (normal object)// JavaThread*:54 epoch:2 unused:1 age:4 biased_lock:1 lock:2 (biased object)// PromotedObject*:61 ---------------------&gt;| promo_bits:3 -----&gt;| (CMS promoted object)// size:64 -----------------------------------------------------&gt;| (CMS free block)//// unused:25 hash:31 --&gt;| cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; normal object)// JavaThread*:54 epoch:2 cms_free:1 age:4 biased_lock:1 lock:2 (COOPs &amp;&amp; biased object)// narrowOop:32 unused:24 cms_free:1 unused:4 promo_bits:3 -----&gt;| (COOPs &amp;&amp; CMS promoted object)// unused:21 size:35 --&gt;| cms_free:1 unused:7 ------------------&gt;| (COOPs &amp;&amp; CMS free block) synchronized的横切面详解 synchronized原理 升级过程 汇编实现 vs reentrantLock的区别 java源码层级synchronized(o) 字节码层级monitorenter moniterexit JVM层级（Hotspot）12345678910111213package com.mashibing.insidesync;import org.openjdk.jol.info.ClassLayout;public class T01_Sync1 &#123; public static void main(String[] args) &#123; Object o = new Object(); System.out.println(ClassLayout.parseInstance(o).toPrintable()); &#125;&#125; 12345678com.mashibing.insidesync.T01_Sync1$Lock object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 00 00 00 (00000101 00000000 00000000 00000000) (5) 4 4 (object header) 00 00 00 00 (00000000 00000000 00000000 00000000) (0) 8 4 (object header) 49 ce 00 20 (01001001 11001110 00000000 00100000) (536923721) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes total 12345678com.mashibing.insidesync.T02_Sync2$Lock object internals: OFFSET SIZE TYPE DESCRIPTION VALUE 0 4 (object header) 05 90 2e 1e (00000101 10010000 00101110 00011110) (506368005) 4 4 (object header) 1b 02 00 00 (00011011 00000010 00000000 00000000) (539) 8 4 (object header) 49 ce 00 20 (01001001 11001110 00000000 00100000) (536923721) 12 4 (loss due to the next object alignment)Instance size: 16 bytesSpace losses: 0 bytes internal + 4 bytes external = 4 bytes tota InterpreterRuntime:: monitorenter方法 12345678910111213141516171819202122IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif if (PrintBiasedLockingStatistics) &#123; Atomic::inc(BiasedLocking::slow_path_entry_count_addr()); &#125; Handle h_obj(thread, elem-&gt;obj()); assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()), \"must be NULL or an object\"); if (UseBiasedLocking) &#123; // Retry fast entry if bias is revoked to avoid unnecessary inflation ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), true, CHECK); &#125; else &#123; ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK); &#125; assert(Universe::heap()-&gt;is_in_reserved_or_null(elem-&gt;obj()), \"must be NULL or an object\");#ifdef ASSERT thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END synchronizer.cpp revoke_and_rebias 12345678910111213141516void ObjectSynchronizer::fast_enter(Handle obj, BasicLock* lock, bool attempt_rebias, TRAPS) &#123; if (UseBiasedLocking) &#123; if (!SafepointSynchronize::is_at_safepoint()) &#123; BiasedLocking::Condition cond = BiasedLocking::revoke_and_rebias(obj, attempt_rebias, THREAD); if (cond == BiasedLocking::BIAS_REVOKED_AND_REBIASED) &#123; return; &#125; &#125; else &#123; assert(!attempt_rebias, \"can not rebias toward VM thread\"); BiasedLocking::revoke_at_safepoint(obj); &#125; assert(!obj-&gt;mark()-&gt;has_bias_pattern(), \"biases should be revoked by now\"); &#125; slow_enter (obj, lock, THREAD) ;&#125; 123456789101112131415161718192021222324252627282930313233343536void ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) &#123; markOop mark = obj-&gt;mark(); assert(!mark-&gt;has_bias_pattern(), \"should not see bias pattern here\"); if (mark-&gt;is_neutral()) &#123; // Anticipate successful CAS -- the ST of the displaced mark must // be visible &lt;= the ST performed by the CAS. lock-&gt;set_displaced_header(mark); if (mark == (markOop) Atomic::cmpxchg_ptr(lock, obj()-&gt;mark_addr(), mark)) &#123; TEVENT (slow_enter: release stacklock) ; return ; &#125; // Fall through to inflate() ... &#125; else if (mark-&gt;has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark-&gt;locker())) &#123; assert(lock != mark-&gt;locker(), \"must not re-lock the same lock\"); assert(lock != (BasicLock*)obj-&gt;mark(), \"don't relock with same BasicLock\"); lock-&gt;set_displaced_header(NULL); return; &#125;#if 0 // The following optimization isn't particularly useful. if (mark-&gt;has_monitor() &amp;&amp; mark-&gt;monitor()-&gt;is_entered(THREAD)) &#123; lock-&gt;set_displaced_header (NULL) ; return ; &#125;#endif // The object header will never be displaced to this lock, // so it does not matter what the value is, except that it // must be non-zero to avoid looking like a re-entrant lock, // and must not look locked either. lock-&gt;set_displaced_header(markOopDesc::unused_mark()); ObjectSynchronizer::inflate(THREAD, obj())-&gt;enter(THREAD);&#125; inflate方法：膨胀为重量级锁 锁升级过程JDK8 markword实现表： markword 无锁 - 偏向锁 - 轻量级锁 （自旋锁，自适应自旋）- 重量级锁 synchronized优化的过程和markword息息相关 用markword中最低的三位代表锁状态 其中1位是偏向锁位 两位是普通锁位 Object o = new Object()锁 = 0 01 无锁态 o.hashCode()001 + hashcode 1200000001 10101101 00110100 0011011001011001 00000000 00000000 00000000 little endian big endian 00000000 00000000 00000000 01011001 00110110 00110100 10101101 00000000 默认synchronized(o)00 -&gt; 轻量级锁默认情况 偏向锁有个时延，默认是4秒why? 因为JVM虚拟机自己有一些默认启动的线程，里面有好多sync代码，这些sync代码启动时就知道肯定会有竞争，如果使用偏向锁，就会造成偏向锁不断的进行锁撤销和锁升级的操作，效率较低。 1-XX:BiasedLockingStartupDelay=0 如果设定上述参数new Object () - &gt; 101 偏向锁 -&gt;线程ID为0 -&gt; Anonymous BiasedLock打开偏向锁，new出来的对象，默认就是一个可偏向匿名对象101 如果有线程上锁上偏向锁，指的就是，把markword的线程ID改为自己线程ID的过程偏向锁不可重偏向 批量偏向 批量撤销 如果有线程竞争撤销偏向锁，升级轻量级锁线程在自己的线程栈生成LockRecord ，用CAS操作将markword设置为指向自己这个线程的LR的指针，设置成功者得到锁 如果竞争加剧竞争加剧：有线程超过10次自旋， -XX:PreBlockSpin， 或者自旋线程数超过CPU核数的一半， 1.6之后，加入自适应自旋 Adapative Self Spinning ， JVM自己控制升级重量级锁：-&gt; 向操作系统申请资源，linux mutex , CPU从3级-0级系统调用，线程挂起，进入等待队列，等待操作系统的调度，然后再映射回用户空间 (以上实验环境是JDK11，打开就是偏向锁，而JDK8默认对象头是无锁) 偏向锁默认是打开的，但是有一个时延，如果要观察到偏向锁，应该设定参数 没错，我就是厕所所长 加锁，指的是锁定对象 锁升级的过程 JDK较早的版本 OS的资源 互斥量 用户态 -&gt; 内核态的转换 重量级 效率比较低 现代版本进行了优化 无锁 - 偏向锁 -轻量级锁（自旋锁）-重量级锁 偏向锁 - markword 上记录当前线程指针，下次同一个线程加锁的时候，不需要争用，只需要判断线程指针是否同一个，所以，偏向锁，偏向加锁的第一个线程 。hashCode备份在线程栈上 线程销毁，锁降级为无锁 有争用 - 锁升级为轻量级锁 - 每个线程有自己的LockRecord在自己的线程栈上，用CAS去争用markword的LR的指针，指针指向哪个线程的LR，哪个线程就拥有锁 自旋超过10次，升级为重量级锁 - 如果太多线程自旋 CPU消耗过大，不如升级为重量级锁，进入等待队列（不消耗CPU）-XX:PreBlockSpin 自旋锁在 JDK1.4.2 中引入，使用 -XX:+UseSpinning 来开启。JDK 6 中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。 自适应自旋锁意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。 偏向锁由于有锁撤销的过程revoke，会消耗系统资源，所以，在锁争用特别激烈的时候，用偏向锁未必效率高。还不如直接使用轻量级锁。 synchronized最底层实现123456789101112131415public class T &#123; static volatile int i = 0; public static void n() &#123; i++; &#125; public static synchronized void m() &#123;&#125; publics static void main(String[] args) &#123; for(int j=0; j&lt;1000_000; j++) &#123; m(); n(); &#125; &#125;&#125; java -XX:+UnlockDiagonositicVMOptions -XX:+PrintAssembly T C1 Compile Level 1 (一级优化) C2 Compile Level 2 (二级优化) 找到m() n()方法的汇编码，会看到 lock comxchg …..指令 synchronized vs Lock (CAS)123456在高争用 高耗时的环境下synchronized效率更高在低争用 低耗时的环境下CAS效率更高synchronized到重量级之后是等待队列（不消耗CPU）CAS（等待期间消耗CPU）一切以实测为准 锁消除 lock eliminate1234public void add(String str1,String str2)&#123; StringBuffer sb = new StringBuffer(); sb.append(str1).append(str2);&#125; 我们都知道 StringBuffer 是线程安全的，因为它的关键方法都是被 synchronized 修饰过的，但我们看上面这段代码，我们会发现，sb 这个引用只会在 add 方法中使用，不可能被其它线程引用（因为是局部变量，栈私有），因此 sb 是不可能共享的资源，JVM 会自动消除 StringBuffer 对象内部的锁。 锁粗化 lock coarsening12345678910public String test(String str)&#123; int i = 0; StringBuffer sb = new StringBuffer(): while(i &lt; 100)&#123; sb.append(str); i++; &#125; return sb.toString():&#125; JVM 会检测到这样一连串的操作都对同一个对象加锁（while 循环内 100 次执行 append，没有锁粗化的就要进行 100 次加锁/解锁），此时 JVM 就会将加锁的范围粗化到这一连串的操作的外部（比如 while 虚幻体外），使得这一连串操作只需要加一次锁即可。 锁降级（不重要）https://www.zhihu.com/question/63859501 其实，只被VMThread访问，降级也就没啥意义了。所以可以简单认为锁降级不存在！ 超线程一个ALU + 两组Registers + PC volatile的用途1.线程可见性12345678910111213141516171819package com.mashibing.testvolatile;public class T01_ThreadVisibility &#123; private static volatile boolean flag = true; public static void main(String[] args) throws InterruptedException &#123; new Thread(()-&gt; &#123; while (flag) &#123; //do sth &#125; System.out.println(\"end\"); &#125;, \"server\").start(); Thread.sleep(1000); flag = false; &#125;&#125; 2.防止指令重排序问题：DCL单例需不需要加volatile？CPU的基础知识 缓存行对齐缓存行64个字节是CPU同步的基本单位，缓存行隔离会比伪共享效率要高Disruptor 123456789101112131415161718192021222324252627282930313233343536373839package com.mashibing.juc.c_028_FalseSharing;public class T02_CacheLinePadding &#123; private static class Padding &#123; public volatile long p1, p2, p3, p4, p5, p6, p7; // &#125; private static class T extends Padding &#123; public volatile long x = 0L; &#125; public static T[] arr = new T[2]; static &#123; arr[0] = new T(); arr[1] = new T(); &#125; public static void main(String[] args) throws Exception &#123; Thread t1 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_0000L; i++) &#123; arr[0].x = i; &#125; &#125;); Thread t2 = new Thread(()-&gt;&#123; for (long i = 0; i &lt; 1000_0000L; i++) &#123; arr[1].x = i; &#125; &#125;); final long start = System.nanoTime(); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println((System.nanoTime() - start)/100_0000); &#125;&#125; MESI 伪共享 合并写CPU内部的4个字节的Buffer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package com.mashibing.juc.c_029_WriteCombining;public final class WriteCombining &#123; private static final int ITERATIONS = Integer.MAX_VALUE; private static final int ITEMS = 1 &lt;&lt; 24; private static final int MASK = ITEMS - 1; private static final byte[] arrayA = new byte[ITEMS]; private static final byte[] arrayB = new byte[ITEMS]; private static final byte[] arrayC = new byte[ITEMS]; private static final byte[] arrayD = new byte[ITEMS]; private static final byte[] arrayE = new byte[ITEMS]; private static final byte[] arrayF = new byte[ITEMS]; public static void main(final String[] args) &#123; for (int i = 1; i &lt;= 3; i++) &#123; System.out.println(i + \" SingleLoop duration (ns) = \" + runCaseOne()); System.out.println(i + \" SplitLoop duration (ns) = \" + runCaseTwo()); &#125; &#125; public static long runCaseOne() &#123; long start = System.nanoTime(); int i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayA[slot] = b; arrayB[slot] = b; arrayC[slot] = b; arrayD[slot] = b; arrayE[slot] = b; arrayF[slot] = b; &#125; return System.nanoTime() - start; &#125; public static long runCaseTwo() &#123; long start = System.nanoTime(); int i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayA[slot] = b; arrayB[slot] = b; arrayC[slot] = b; &#125; i = ITERATIONS; while (--i != 0) &#123; int slot = i &amp; MASK; byte b = (byte) i; arrayD[slot] = b; arrayE[slot] = b; arrayF[slot] = b; &#125; return System.nanoTime() - start; &#125;&#125; 指令重排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.mashibing.jvm.c3_jmm;public class T04_Disorder &#123; private static int x = 0, y = 0; private static int a = 0, b =0; public static void main(String[] args) throws InterruptedException &#123; int i = 0; for(;;) &#123; i++; x = 0; y = 0; a = 0; b = 0; Thread one = new Thread(new Runnable() &#123; public void run() &#123; //由于线程one先启动，下面这句话让它等一等线程two. 读着可根据自己电脑的实际性能适当调整等待时间. //shortWait(100000); a = 1; x = b; &#125; &#125;); Thread other = new Thread(new Runnable() &#123; public void run() &#123; b = 1; y = a; &#125; &#125;); one.start();other.start(); one.join();other.join(); String result = \"第\" + i + \"次 (\" + x + \",\" + y + \"）\"; if(x == 0 &amp;&amp; y == 0) &#123; System.err.println(result); break; &#125; else &#123; //System.out.println(result); &#125; &#125; &#125; public static void shortWait(long interval)&#123; long start = System.nanoTime(); long end; do&#123; end = System.nanoTime(); &#125;while(start + interval &gt;= end); &#125;&#125; volatile如何解决指令重排序1: volatile i 2: ACC_VOLATILE 3: JVM的内存屏障 4：hotspot实现 bytecodeinterpreter.cpp 12345int field_offset = cache-&gt;f2_as_index(); if (cache-&gt;is_volatile()) &#123; if (support_IRIW_for_not_multiple_copy_atomic_cpu) &#123; OrderAccess::fence(); &#125; orderaccess_linux_x86.inline.hpp 12345678910inline void OrderAccess::fence() &#123; if (os::is_MP()) &#123; // always use locked addl since mfence is sometimes expensive#ifdef AMD64 __asm__ volatile (\"lock; addl $0,0(%%rsp)\" : : : \"cc\", \"memory\");#else __asm__ volatile (\"lock; addl $0,0(%%esp)\" : : : \"cc\", \"memory\");#endif &#125;&#125; 参考资料http://openjdk.java.net/groups/hotspot/docs/HotSpotGlossary.html","categories":[],"tags":[]},{"title":"ThreadLocal","slug":"ThreadLocal","date":"2020-10-19T12:13:17.833Z","updated":"2020-10-19T12:12:51.264Z","comments":true,"path":"2020/10/19/ThreadLocal/","link":"","permalink":"http://yoursite.com/2020/10/19/ThreadLocal/","excerpt":"","text":"ThreadLocal源码解析一、ThreadLocal的使用​ ThreadLoca是一个本地的线程变量，他能够做到线程与线程之间的隔离，它其中填充的变量只属于本线程，它为变量在每个线程中都创建了一个副本，那么每个线程可以访问自己内部的副本变量。 ​ 他的用法也非常简单： 1234ThreadLocal&lt;String&gt; threadLocal=new ThreadLocal&lt;&gt;();threadLocal.set(\"1\");threadLocal.get();threadLocal.remove(); 以上的api就是ThreadLocal的主要api，主要就是这三个，一个是设置线程变量，一个是获取，最后是清空。ThreadLocal的泛型的类型就是所要存储对象的类型。set(“1”)执行以后就相当于在本线程中存在了一个存储着“1”这个字符串的一个变量，该变量只对本线程可见。 二、ThreadLocal源码分析1.set方法实现分析12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 在set方法中首先获取到了当前的线程t，然后通过getMap方法将t传入获得了一个ThreadLocalMap。来看下getMap的代码： 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 最终返回了一个t中的变量threadLocals也就是说这个变量是属于线程Thread类的，因为t是当前线程对象。然后看下Thread中的这个变量的定义： 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 默认是个null值，回到set方法，做了个map！=null的判断，因为初始化的时候这个map是个null所以会走else分支，执行 createMap(t, value)方法。在这个方法中最终创建了一个ThreadLocalMap并且赋值给threadLocals。在创建的时候传入了一个this作为key然后传入的值作为value，此时的this就是当前threadLocal对象。最终也就是创建了一个map并且map中的key为当前threadLocal对象，value为传入的数据。 123void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 然后看下ThreadLocalMap的构造方法， 123456789101112/** * Construct a new map initially containing (firstKey, firstValue). * ThreadLocalMaps are constructed lazily, so we only create * one when we have at least one entry to put in it. */ThreadLocalMap(ThreadLocal firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY);&#125; 会发现在其中创建了一个Entry数组，数组的大小为初始化容量16，如果点击进去会发现Entry类继承了一个虚引用。然后将key进行hash计算。最终执行了一个setThreshold方法扩大了threshold阈值。也就是将来这个参数作为扩容的标志，如果map的长度大于了总长度的三分之二就要进行扩容。至此形成了一个图： ThreadLocal ​ 图中左侧是虚拟机栈右侧是堆，左侧存放的是对象的引用，右侧是实际的对象开辟的内存空间，当创建了一个ThreadLocal对象以后，栈中的引用是强指向的关系，同时通过上边的分析得知，这个ThreadLocal对象也作为了ThreadLocalMap的key，然后ThreadLoacalMap的主要数据结构就是一个Entry数组，所以也就是Entry中的某个entry中的key指向了创建的ThreadLocal对象，由于entry继承了WeakReference类，同时将其key的指向改变成弱引用，也就是最终形成了key到ThreadLocal对象的引用变成了若引用指向。 ​ 在栈中还有一个当前线程对象的引用，它指向了堆中的线程对象，而真正的ThreadLocalMap正是存储在每个线程的threadLocals变量中，也就是threadLocals指向了这个map，也就印证了为什么实现了线程之间的隔离，就是因为这个map是放在每个线程之中的。 ​ 这样设置成虚引用的好处是什么？这是因为当方法执行结束以后，栈中的数据会随之弹栈，然后这时候栈中的引用也就不存在了，如果key到ThreadLocal对象是一个强引用那么此时ThreadLocal对象则不能被回收，但是此时如果线程还没有销毁，也就是线程的引用还存在着，那么ThreadLocalMap的也不会被回收，但是显然这个map不会被使用了，因为栈中的ThreadLocal的引用已消失，也就是获取不到key值了，所以随着这样的情况反复出现就会造成内存泄漏，而如果设置成弱引用就会尽量避免key值得内存泄漏，因为key是若引用指向了ThreadLocal对象所以在下次GC发生时就会回收掉ThreadLocal对象。但是这样也避免不了value得内存泄漏的发生，所以在阿里规约中约定必须要使用ThreadLocal中得remove方法进行map的移除操作。","categories":[],"tags":[]},{"title":"GC和实战","slug":"GC和实战","date":"2020-09-24T11:25:07.677Z","updated":"2020-10-20T00:27:46.085Z","comments":true,"path":"2020/09/24/GC和实战/","link":"","permalink":"http://yoursite.com/2020/09/24/GC%E5%92%8C%E5%AE%9E%E6%88%98/","excerpt":"","text":"GC和GC TuningGC的基础知识1.什么是垃圾 C语言申请内存：malloc free C++： new delete c/C++ 手动回收内存 Java: new ？ 自动内存回收，编程上简单，系统不容易出错，手动释放内存，容易出两种类型的问题： 忘记回收 多次回收 没有任何引用指向的一个对象或者多个对象（循环引用） 2.如何定位垃圾 引用计数（ReferenceCount） 根可达算法(RootSearching) 3.常见的垃圾回收算法 标记清除(mark sweep) - 位置不连续 产生碎片 效率偏低（两遍扫描） 拷贝算法 (copying) - 没有碎片，浪费空间 标记压缩(mark compact) - 没有碎片，效率偏低（两遍扫描，指针需要调整） 4.JVM内存分代模型（用于分代垃圾回收算法） 部分垃圾回收器使用的模型 除Epsilon ZGC Shenandoah之外的GC都是使用逻辑分代模型 G1是逻辑分代，物理不分代 除此之外不仅逻辑分代，而且物理分代 新生代 + 老年代 + 永久代（1.7）Perm Generation/ 元数据区(1.8) Metaspace 永久代 元数据 - Class 永久代必须指定大小限制 ，元数据可以设置，也可以不设置，无上限（受限于物理内存） 字符串常量 1.7 - 永久代，1.8 - 堆 MethodArea逻辑概念 - 永久代、元数据 新生代 = Eden + 2个suvivor区 YGC回收之后，大多数的对象会被回收，活着的进入s0 再次YGC，活着的对象eden + s0 -&gt; s1 再次YGC，eden + s1 -&gt; s0 年龄足够 -&gt; 老年代 （15 CMS 6） s区装不下 -&gt; 老年代 老年代 顽固分子 老年代满了FGC Full GC GC Tuning (Generation) 尽量减少FGC MinorGC = YGC MajorGC = FGC 对象分配过程图 动态年龄：（不重要）https://www.jianshu.com/p/989d3b06a49d 分配担保：（不重要）YGC期间 survivor区空间不够了 空间担保直接进入老年代参考：https://cloud.tencent.com/developer/article/1082730 5.常见的垃圾回收器 常用垃圾回收器 垃圾回收器的发展路线，是随着内存越来越大的过程而演进从分代算法演化到不分代算法Serial算法 几十兆Parallel算法 几个GCMS 几十个G - 承上启下，开始并发回收 -.- 三色标记 - JDK诞生 Serial追随 提高效率，诞生了PS，为了配合CMS，诞生了PN，CMS是1.4版本后期引入，CMS是里程碑式的GC，它开启了并发回收的过程，但是CMS毛病较多，因此目前任何一个JDK版本默认是CMS并发垃圾回收是因为无法忍受STW Serial 年轻代 串行回收 PS 年轻代 并行回收 ParNew 年轻代 配合CMS的并行回收 SerialOld ParallelOld ConcurrentMarkSweep 老年代 并发的， 垃圾回收和应用程序同时运行，降低STW的时间(200ms)CMS问题比较多，所以现在没有一个版本默认是CMS，只能手工指定CMS既然是MarkSweep，就一定会有碎片化的问题，碎片到达一定程度，CMS的老年代分配对象分配不下的时候，使用SerialOld 进行老年代回收想象一下：PS + PO -&gt; 加内存 换垃圾回收器 -&gt; PN + CMS + SerialOld（几个小时 - 几天的STW）几十个G的内存，单线程回收 -&gt; G1 + FGC 几十个G -&gt; 上T内存的服务器 ZGC算法：三色标记 + Incremental Update G1(200ms - 10ms)算法：三色标记 + SATB ZGC (10ms - 1ms) PK C++ 算法：ColoredPointers + LoadBarrier Shenandoah算法：ColoredPointers + WriteBarrier Eplison PS 和 PN区别的延伸阅读：▪https://docs.oracle.com/en/java/javase/13/gctuning/ergonomics.html#GUID-3D0BB91E-9BFF-4EBB-B523-14493A860E73 垃圾收集器跟内存大小的关系 Serial 几十兆 PS 上百兆 - 几个G CMS - 20G G1 - 上百G ZGC - 4T - 16T（JDK13） 1.8默认的垃圾回收：PS + ParallelOld 常见垃圾回收器组合参数设定：(1.8) -XX:+UseSerialGC = Serial New (DefNew) + Serial Old 小型程序。默认情况下不会是这种选项，HotSpot会根据计算及配置和JDK版本自动选择收集器 -XX:+UseParNewGC = ParNew + SerialOld 这个组合已经很少用（在某些版本中已经废弃） https://stackoverflow.com/questions/34962257/why-remove-support-for-parnewserialold-anddefnewcms-in-the-future -XX:+UseConc(urrent)MarkSweepGC = ParNew + CMS + Serial Old -XX:+UseParallelGC = Parallel Scavenge + Parallel Old (1.8默认) 【PS + SerialOld】 -XX:+UseParallelOldGC = Parallel Scavenge + Parallel Old -XX:+UseG1GC = G1 Linux中没找到默认GC的查看方法，而windows中会打印UseParallelGC java +XX:+PrintCommandLineFlags -version 通过GC的日志来分辨 Linux下1.8版本默认的垃圾回收器到底是什么？ 1.8.0_181 默认（看不出来）Copy MarkCompact 1.8.0_222 默认 PS + PO JVM调优第一步，了解JVM常用命令行参数 JVM的命令行参数参考：https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html HotSpot参数分类 标准： - 开头，所有的HotSpot都支持 非标准：-X 开头，特定版本HotSpot支持特定命令 不稳定：-XX 开头，下个版本可能取消 java -version java -X java -XX:+PrintFlagsWithComments //只有debug版本能用 试验用程序： 12345678910111213 import java.util.List; import java.util.LinkedList; public class HelloGC &#123; public static void main(String[] args) &#123; System.out.println(\"HelloGC!\"); List list = new LinkedList(); for(;;) &#123; byte[] b = new byte[1024*1024]; list.add(b); &#125; &#125;&#125; 区分概念：内存泄漏memory leak，内存溢出out of memory java -XX:+PrintCommandLineFlags HelloGC java -Xmn10M -Xms40M -Xmx60M -XX:+PrintCommandLineFlags -XX:+PrintGC HelloGCPrintGCDetails PrintGCTimeStamps PrintGCCauses java -XX:+UseConcMarkSweepGC -XX:+PrintCommandLineFlags HelloGC java -XX:+PrintFlagsInitial 默认参数值 java -XX:+PrintFlagsFinal 最终参数值 java -XX:+PrintFlagsFinal | grep xxx 找到对应的参数 java -XX:+PrintFlagsFinal -version |grep GC java -XX:+PrintFlagsFinal -version | wc -l共728个参数 PS GC日志详解每种垃圾回收器的日志格式是不同的！ PS日志格式 GC日志详解 heap dump部分： 12eden space 5632K, 94% used [0x00000000ff980000,0x00000000ffeb3e28,0x00000000fff00000) 后面的内存地址指的是，起始地址，使用空间结束地址，整体空间结束地址 GCHeapDump total = eden + 1个survivor 调优前的基础概念： 吞吐量：用户代码时间 /（用户代码执行时间 + 垃圾回收时间） 响应时间：STW越短，响应时间越好 所谓调优，首先确定，追求啥？吞吐量优先，还是响应时间优先？还是在满足一定的响应时间的情况下，要求达到多大的吞吐量… 问题： 科学计算，吞吐量。数据挖掘，thrput。吞吐量优先的一般：（PS + PO） 响应时间：网站 GUI API （1.8 G1） 什么是调优？ 根据需求进行JVM规划和预调优 优化运行JVM运行环境（慢，卡顿） 解决JVM运行过程中出现的各种问题(OOM) 调优，从规划开始 调优，从业务场景开始，没有业务场景的调优都是耍流氓 无监控（压力测试，能看到结果），不调优 步骤： 熟悉业务场景（没有最好的垃圾回收器，只有最合适的垃圾回收器） 响应时间、停顿时间 [CMS G1 ZGC] （需要给用户作响应） 吞吐量 = 用户时间 /( 用户时间 + GC时间) [PS] 选择回收器组合 计算内存需求（经验值 1.5G 16G） 选定CPU（越高越好） 设定年代大小、升级年龄 设定日志参数 -Xloggc:/opt/xxx/logs/xxx-xxx-gc-%t.log -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=20M -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCCause 或者每天产生一个日志文件 观察日志情况 案例1：垂直电商，最高每日百万订单，处理订单系统需要什么样的服务器配置？ 这个问题比较业余，因为很多不同的服务器配置都能支撑(1.5G 16G) 1小时360000集中时间段， 100个订单/秒，（找一小时内的高峰期，1000订单/秒） 经验值， 非要计算：一个订单产生需要多少内存？512K * 1000 500M内存 专业一点儿问法：要求响应时间100ms 压测！ 案例2：12306遭遇春节大规模抢票应该如何支撑？ 12306应该是中国并发量最大的秒杀网站： 号称并发量100W最高 CDN -&gt; LVS -&gt; NGINX -&gt; 业务系统 -&gt; 每台机器1W并发（10K问题） 100台机器 普通电商订单 -&gt; 下单 -&gt;订单系统（IO）减库存 -&gt;等待用户付款 12306的一种可能的模型： 下单 -&gt; 减库存 和 订单(redis kafka) 同时异步进行 -&gt;等付款 减库存最后还会把压力压到一台服务器 可以做分布式本地库存 + 单独服务器做库存均衡 大流量的处理方法：分而治之 怎么得到一个事务会消耗多少内存？ 弄台机器，看能承受多少TPS？是不是达到目标？扩容或调优，让它达到 用压测来确定 优化环境 有一个50万PV的资料类网站（从磁盘提取文档到内存）原服务器32位，1.5G的堆，用户反馈网站比较缓慢，因此公司决定升级，新的服务器为64位，16G的堆内存，结果用户反馈卡顿十分严重，反而比以前效率更低了 为什么原网站慢?很多用户浏览数据，很多数据load到内存，内存不足，频繁GC，STW长，响应时间变慢 为什么会更卡顿？内存越大，FGC时间越长 咋办？PS -&gt; PN + CMS 或者 G1 系统CPU经常100%，如何调优？(面试高频)CPU100%那么一定有线程在占用系统资源， 找出哪个进程cpu高（top） 该进程中的哪个线程cpu高（top -Hp） 导出该线程的堆栈 (jstack) 查找哪个方法（栈帧）消耗时间 (jstack) 工作线程占比高 | 垃圾回收线程占比高 系统内存飙高，如何查找问题？（面试高频） 导出堆内存 (jmap) 分析 (jhat jvisualvm mat jprofiler … ) 如何监控JVM jstat jvisualvm jprofiler arthas top… 解决JVM运行中的问题一个案例理解常用工具 测试代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.mashibing.jvm.gc;import java.math.BigDecimal;import java.util.ArrayList;import java.util.Date;import java.util.List;import java.util.concurrent.ScheduledThreadPoolExecutor;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;/** * 从数据库中读取信用数据，套用模型，并把结果进行记录和传输 */public class T15_FullGC_Problem01 &#123; private static class CardInfo &#123; BigDecimal price = new BigDecimal(0.0); String name = \"张三\"; int age = 5; Date birthdate = new Date(); public void m() &#123;&#125; &#125; private static ScheduledThreadPoolExecutor executor = new ScheduledThreadPoolExecutor(50, new ThreadPoolExecutor.DiscardOldestPolicy()); public static void main(String[] args) throws Exception &#123; executor.setMaximumPoolSize(50); for (;;)&#123; modelFit(); Thread.sleep(100); &#125; &#125; private static void modelFit()&#123; List&lt;CardInfo&gt; taskList = getAllCardInfo(); taskList.forEach(info -&gt; &#123; // do something executor.scheduleWithFixedDelay(() -&gt; &#123; //do sth with info info.m(); &#125;, 2, 3, TimeUnit.SECONDS); &#125;); &#125; private static List&lt;CardInfo&gt; getAllCardInfo()&#123; List&lt;CardInfo&gt; taskList = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 100; i++) &#123; CardInfo ci = new CardInfo(); taskList.add(ci); &#125; return taskList; &#125;&#125; java -Xms200M -Xmx200M -XX:+PrintGC com.mashibing.jvm.gc.T15_FullGC_Problem01 一般是运维团队首先受到报警信息（CPU Memory） top命令观察到问题：内存不断增长 CPU占用率居高不下 top -Hp 观察进程中的线程，哪个线程CPU和内存占比高 jps定位具体java进程jstack 定位线程状况，重点关注：WAITING BLOCKEDeg.waiting on &lt;0x0000000088ca3310&gt; (a java.lang.Object)假如有一个进程中100个线程，很多线程都在waiting on ，一定要找到是哪个线程持有这把锁怎么找？搜索jstack dump的信息，找 ，看哪个线程持有这把锁RUNNABLE作业：1：写一个死锁程序，用jstack观察 2 ：写一个程序，一个线程持有锁不释放，其他线程等待 为什么阿里规范里规定，线程的名称（尤其是线程池）都要写有意义的名称怎么样自定义线程池里的线程名称？（自定义ThreadFactory） jinfo pid jstat -gc 动态观察gc情况 / 阅读GC日志发现频繁GC / arthas观察 / jconsole/jvisualVM/ Jprofiler（最好用）jstat -gc 4655 500 : 每个500个毫秒打印GC的情况如果面试官问你是怎么定位OOM问题的？如果你回答用图形界面（错误）1：已经上线的系统不用图形界面用什么？（cmdline arthas）2：图形界面到底用在什么地方？测试！测试的时候进行监控！（压测观察） jmap - histo 4655 | head -20，查找有多少对象产生 jmap -dump:format=b,file=xxx pid ： 线上系统，内存特别大，jmap执行期间会对进程产生很大影响，甚至卡顿（电商不适合）1：设定了参数HeapDump，OOM的时候会自动产生堆转储文件（不是很专业，因为多有监控，内存增长就会报警）2：很多服务器备份（高可用），停掉这台服务器对其他服务器不影响3：在线定位(一般小点儿公司用不到) 4：在测试环境中压测（产生类似内存增长问题，在堆还不是很大的时候进行转储） java -Xms20M -Xmx20M -XX:+UseParallelGC -XX:+HeapDumpOnOutOfMemoryError com.mashibing.jvm.gc.T15_FullGC_Problem01 使用MAT / jhat /jvisualvm 进行dump文件分析 https://www.cnblogs.com/baihuitestsoftware/articles/6406271.htmljhat -J-mx512M xxx.dumphttp://192.168.17.11:7000拉到最后：找到对应链接可以使用OQL查找特定问题对象 找到代码的问题 jconsole远程连接 程序启动加入参数： 1java -Djava.rmi.server.hostname=192.168.17.11 -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=11111 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false XXX 如果遭遇 Local host name unknown：XXX的错误，修改/etc/hosts文件，把XXX加入进去 12192.168.17.11 basic localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 关闭linux防火墙（实战中应该打开对应端口） 12service iptables stopchkconfig iptables off #永久关闭 windows上打开 jconsole远程连接 192.168.17.11:11111 jvisualvm远程连接 https://www.cnblogs.com/liugh/p/7620336.html （简单做法） jprofiler (收费)arthas在线排查工具 为什么需要在线排查？ 在生产上我们经常会碰到一些不好排查的问题，例如线程安全问题，用最简单的threaddump或者heapdump不好查到问题原因。为了排查这些问题，有时我们会临时加一些日志，比如在一些关键的函数里打印出入参，然后重新打包发布，如果打了日志还是没找到问题，继续加日志，重新打包发布。对于上线流程复杂而且审核比较严的公司，从改代码到上线需要层层的流转，会大大影响问题排查的进度。 jvm观察jvm信息 thread定位线程问题 dashboard 观察系统情况 heapdump + jhat分析 jad反编译 动态代理生成类的问题定位 第三方的类（观察代码） 版本问题（确定自己最新提交的版本是不是被使用） redefine 热替换 目前有些限制条件：只能改方法实现（方法已经运行完成），不能改方法名， 不能改属性 m() -&gt; mm() sc - search class watch - watch method 没有包含的功能：jmap GC算法的基础概念 Card Table由于做YGC时，需要扫描整个OLD区，效率非常低，所以JVM设计了CardTable， 如果一个OLD区CardTable中有对象指向Y区，就将它设为Dirty，下次扫描时，只需要扫描Dirty Card在结构上，Card Table用BitMap来实现 CMSCMS的问题 Memory Fragmentation -XX:+UseCMSCompactAtFullCollection-XX:CMSFullGCsBeforeCompaction 默认为0 指的是经过多少次FGC才进行压缩 Floating Garbage Concurrent Mode Failure产生：if the concurrent collector is unable to finish reclaiming the unreachable objects before the tenured generation fills up, or if an allocation cannot be satisfiedwith the available free space blocks in the tenured generation, then theapplication is paused and the collection is completed with all the applicationthreads stopped 解决方案：降低触发CMS的阈值 PromotionFailed 解决方案类似，保持老年代有足够的空间 –XX:CMSInitiatingOccupancyFraction 92% 可以降低这个值，让CMS保持老年代足够的空间 CMS日志分析执行命令：java -Xms20M -Xmx20M -XX:+PrintGCDetails -XX:+UseConcMarkSweepGC com.mashibing.jvm.gc.T15_FullGC_Problem01 [GC (Allocation Failure) [ParNew: 6144K-&gt;640K(6144K), 0.0265885 secs] 6585K-&gt;2770K(19840K), 0.0268035 secs] [Times: user=0.02 sys=0.00, real=0.02 secs] ParNew：年轻代收集器 6144-&gt;640：收集前后的对比 （6144）：整个年轻代容量 6585 -&gt; 2770：整个堆的情况 （19840）：整个堆大小 1234567891011121314151617181920212223242526[GC (CMS Initial Mark) [1 CMS-initial-mark: 8511K(13696K)] 9866K(19840K), 0.0040321 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] //8511 (13696) : 老年代使用（最大） //9866 (19840) : 整个堆使用（最大）[CMS-concurrent-mark-start][CMS-concurrent-mark: 0.018/0.018 secs] [Times: user=0.01 sys=0.00, real=0.02 secs] //这里的时间意义不大，因为是并发执行[CMS-concurrent-preclean-start][CMS-concurrent-preclean: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] //标记Card为Dirty，也称为Card Marking[GC (CMS Final Remark) [YG occupancy: 1597 K (6144 K)][Rescan (parallel) , 0.0008396 secs][weak refs processing, 0.0000138 secs][class unloading, 0.0005404 secs][scrub symbol table, 0.0006169 secs][scrub string table, 0.0004903 secs][1 CMS-remark: 8511K(13696K)] 10108K(19840K), 0.0039567 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] //STW阶段，YG occupancy:年轻代占用及容量 //[Rescan (parallel)：STW下的存活对象标记 //weak refs processing: 弱引用处理 //class unloading: 卸载用不到的class //scrub symbol(string) table: //cleaning up symbol and string tables which hold class-level metadata and //internalized string respectively //CMS-remark: 8511K(13696K): 阶段过后的老年代占用及容量 //10108K(19840K): 阶段过后的堆占用及容量[CMS-concurrent-sweep-start][CMS-concurrent-sweep: 0.005/0.005 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] //标记已经完成，进行并发清理[CMS-concurrent-reset-start][CMS-concurrent-reset: 0.000/0.000 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] //重置内部结构，为下次GC做准备 G1 ▪https://www.oracle.com/technical-resources/articles/java/g1gc.html G1日志详解12345678910111213141516171819202122232425262728293031323334353637[GC pause (G1 Evacuation Pause) (young) (initial-mark), 0.0015790 secs]//young -&gt; 年轻代 Evacuation-&gt; 复制存活对象 //initial-mark 混合回收的阶段，这里是YGC混合老年代回收 [Parallel Time: 1.5 ms, GC Workers: 1] //一个GC线程 [GC Worker Start (ms): 92635.7] [Ext Root Scanning (ms): 1.1] [Update RS (ms): 0.0] [Processed Buffers: 1] [Scan RS (ms): 0.0] [Code Root Scanning (ms): 0.0] [Object Copy (ms): 0.1] [Termination (ms): 0.0] [Termination Attempts: 1] [GC Worker Other (ms): 0.0] [GC Worker Total (ms): 1.2] [GC Worker End (ms): 92636.9] [Code Root Fixup: 0.0 ms] [Code Root Purge: 0.0 ms] [Clear CT: 0.0 ms] [Other: 0.1 ms] [Choose CSet: 0.0 ms] [Ref Proc: 0.0 ms] [Ref Enq: 0.0 ms] [Redirty Cards: 0.0 ms] [Humongous Register: 0.0 ms] [Humongous Reclaim: 0.0 ms] [Free CSet: 0.0 ms] [Eden: 0.0B(1024.0K)-&gt;0.0B(1024.0K) Survivors: 0.0B-&gt;0.0B Heap: 18.8M(20.0M)-&gt;18.8M(20.0M)] [Times: user=0.00 sys=0.00, real=0.00 secs] //以下是混合回收其他阶段[GC concurrent-root-region-scan-start][GC concurrent-root-region-scan-end, 0.0000078 secs][GC concurrent-mark-start]//无法evacuation，进行FGC[Full GC (Allocation Failure) 18M-&gt;18M(20M), 0.0719656 secs] [Eden: 0.0B(1024.0K)-&gt;0.0B(1024.0K) Survivors: 0.0B-&gt;0.0B Heap: 18.8M(20.0M)-&gt;18.8M(20.0M)], [Metaspace: 3876K-&gt;3876K(1056768K)] [Times: user=0.07 sys=0.00, real=0.07 secs] 案例汇总OOM产生的原因多种多样，有些程序未必产生OOM，不断FGC(CPU飙高，但内存回收特别少) （上面案例） 硬件升级系统反而卡顿的问题（见上） 线程池不当运用产生OOM问题（见上）不断的往List里加对象（实在太LOW） smile jira问题实际系统不断重启解决问题 加内存 + 更换垃圾回收器 G1真正问题在哪儿？不知道 tomcat http-header-size过大问题（Hector） lambda表达式导致方法区溢出问题(MethodArea / Perm Metaspace)LambdaGC.java -XX:MaxMetaspaceSize=9M -XX:+PrintGCDetails 1234567891011121314151617181920212223242526272829303132333435363738394041\"C:\\Program Files\\Java\\jdk1.8.0_181\\bin\\java.exe\" -XX:MaxMetaspaceSize=9M -XX:+PrintGCDetails \"-javaagent:C:\\Program Files\\JetBrains\\IntelliJ IDEA Community Edition 2019.1\\lib\\idea_rt.jar=49316:C:\\Program Files\\JetBrains\\IntelliJ IDEA Community Edition 2019.1\\bin\" -Dfile.encoding=UTF-8 -classpath \"C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\charsets.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\deploy.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\access-bridge-64.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\cldrdata.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\dnsns.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\jaccess.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\jfxrt.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\localedata.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\nashorn.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\sunec.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\sunjce_provider.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\sunmscapi.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\sunpkcs11.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\ext\\zipfs.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\javaws.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\jce.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\jfr.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\jfxswt.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\jsse.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\management-agent.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\plugin.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\resources.jar;C:\\Program Files\\Java\\jdk1.8.0_181\\jre\\lib\\rt.jar;C:\\work\\ijprojects\\JVM\\out\\production\\JVM;C:\\work\\ijprojects\\ObjectSize\\out\\artifacts\\ObjectSize_jar\\ObjectSize.jar\" com.mashibing.jvm.gc.LambdaGC[GC (Metadata GC Threshold) [PSYoungGen: 11341K-&gt;1880K(38400K)] 11341K-&gt;1888K(125952K), 0.0022190 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Metadata GC Threshold) [PSYoungGen: 1880K-&gt;0K(38400K)] [ParOldGen: 8K-&gt;1777K(35328K)] 1888K-&gt;1777K(73728K), [Metaspace: 8164K-&gt;8164K(1056768K)], 0.0100681 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] [GC (Last ditch collection) [PSYoungGen: 0K-&gt;0K(38400K)] 1777K-&gt;1777K(73728K), 0.0005698 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Last ditch collection) [PSYoungGen: 0K-&gt;0K(38400K)] [ParOldGen: 1777K-&gt;1629K(67584K)] 1777K-&gt;1629K(105984K), [Metaspace: 8164K-&gt;8156K(1056768K)], 0.0124299 secs] [Times: user=0.06 sys=0.00, real=0.01 secs] java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at sun.instrument.InstrumentationImpl.loadClassAndStartAgent(InstrumentationImpl.java:388) at sun.instrument.InstrumentationImpl.loadClassAndCallAgentmain(InstrumentationImpl.java:411)Caused by: java.lang.OutOfMemoryError: Compressed class space at sun.misc.Unsafe.defineClass(Native Method) at sun.reflect.ClassDefiner.defineClass(ClassDefiner.java:63) at sun.reflect.MethodAccessorGenerator$1.run(MethodAccessorGenerator.java:399) at sun.reflect.MethodAccessorGenerator$1.run(MethodAccessorGenerator.java:394) at java.security.AccessController.doPrivileged(Native Method) at sun.reflect.MethodAccessorGenerator.generate(MethodAccessorGenerator.java:393) at sun.reflect.MethodAccessorGenerator.generateSerializationConstructor(MethodAccessorGenerator.java:112) at sun.reflect.ReflectionFactory.generateConstructor(ReflectionFactory.java:398) at sun.reflect.ReflectionFactory.newConstructorForSerialization(ReflectionFactory.java:360) at java.io.ObjectStreamClass.getSerializableConstructor(ObjectStreamClass.java:1574) at java.io.ObjectStreamClass.access$1500(ObjectStreamClass.java:79) at java.io.ObjectStreamClass$3.run(ObjectStreamClass.java:519) at java.io.ObjectStreamClass$3.run(ObjectStreamClass.java:494) at java.security.AccessController.doPrivileged(Native Method) at java.io.ObjectStreamClass.&lt;init&gt;(ObjectStreamClass.java:494) at java.io.ObjectStreamClass.lookup(ObjectStreamClass.java:391) at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1134) at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1548) at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1509) at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1432) at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178) at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348) at javax.management.remote.rmi.RMIConnectorServer.encodeJRMPStub(RMIConnectorServer.java:727) at javax.management.remote.rmi.RMIConnectorServer.encodeStub(RMIConnectorServer.java:719) at javax.management.remote.rmi.RMIConnectorServer.encodeStubInAddress(RMIConnectorServer.java:690) at javax.management.remote.rmi.RMIConnectorServer.start(RMIConnectorServer.java:439) at sun.management.jmxremote.ConnectorBootstrap.startLocalConnectorServer(ConnectorBootstrap.java:550) at sun.management.Agent.startLocalManagementAgent(Agent.java:137) 直接内存溢出问题（少见）《深入理解Java虚拟机》P59，使用Unsafe分配直接内存，或者使用NIO的问题 栈溢出问题-Xss设定太小 比较一下这两段程序的异同，分析哪一个是更优的写法： 12345Object o = null;for(int i=0; i&lt;100; i++) &#123; o = new Object(); //业务处理&#125; 123for(int i=0; i&lt;100; i++) &#123; Object o = new Object();&#125; 重写finalize引发频繁GC小米云，HBase同步系统，系统通过nginx访问超时报警，最后排查，C++程序员重写finalize引发频繁GC问题为什么C++程序员会重写finalize？（new delete）finalize耗时比较长（200ms） 如果有一个系统，内存一直消耗不超过10%，但是观察GC日志，发现FGC总是频繁产生，会是什么引起的？System.gc() (这个比较Low) Distuptor有个可以设置链的长度，如果过大，然后对象大，消费完不主动释放，会溢出 (来自 死物风情) 用jvm都会溢出，mycat用崩过，1.6.5某个临时版本解析sql子查询算法有问题，9个exists的联合sql就导致生成几百万的对象（来自 死物风情） new 大量线程，会产生 native thread OOM，（low）应该用线程池，解决方案：减少堆空间（太TMlow了）,预留更多内存产生native threadJVM内存占物理内存比例 50% - 80% 近期学生案例SQLLite的类库，批处理的时候会把所有的结果加载内存，有的人一下子更新几十万条数据，结果就产生了内存溢出，定位上用的是排除法，去掉这个模块就没问题，加上该模块就会出问题 java在线解压以及压缩文件造成的内存溢出 java使用opencv造成的卡顿与缓慢 最容易引起崩溃的报表系统 分库分表所引起的系统崩溃 GC常用参数 -Xmn -Xms -Xmx -Xss年轻代 最小堆 最大堆 栈空间 -XX:+UseTLAB使用TLAB，默认打开 -XX:+PrintTLAB打印TLAB的使用情况 -XX:TLABSize设置TLAB大小 -XX:+DisableExplictGCSystem.gc()不管用 ，FGC -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintHeapAtGC -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationConcurrentTime (低)打印应用程序时间 -XX:+PrintGCApplicationStoppedTime （低）打印暂停时长 -XX:+PrintReferenceGC （重要性低）记录回收了多少种不同引用类型的引用 -verbose:class类加载详细过程 -XX:+PrintVMOptions -XX:+PrintFlagsFinal -XX:+PrintFlagsInitial必须会用 -Xloggc:opt/log/gc.log -XX:MaxTenuringThreshold升代年龄，最大值15 锁自旋次数 -XX:PreBlockSpin 热点代码检测参数-XX:CompileThreshold 逃逸分析 标量替换 …这些不建议设置 Parallel常用参数 -XX:SurvivorRatio -XX:PreTenureSizeThreshold大对象到底多大 -XX:MaxTenuringThreshold -XX:+ParallelGCThreads并行收集器的线程数，同样适用于CMS，一般设为和CPU核数相同 -XX:+UseAdaptiveSizePolicy自动选择各区大小比例 CMS常用参数 -XX:+UseConcMarkSweepGC -XX:ParallelCMSThreadsCMS线程数量 -XX:CMSInitiatingOccupancyFraction使用多少比例的老年代后开始CMS收集，默认是68%(近似值)，如果频繁发生SerialOld卡顿，应该调小，（频繁CMS回收） -XX:+UseCMSCompactAtFullCollection在FGC时进行压缩 -XX:CMSFullGCsBeforeCompaction多少次FGC之后进行压缩 -XX:+CMSClassUnloadingEnabled -XX:CMSInitiatingPermOccupancyFraction达到什么比例时进行Perm回收 GCTimeRatio设置GC时间占用程序运行时间的百分比 -XX:MaxGCPauseMillis停顿时间，是一个建议时间，GC会尝试用各种手段达到这个时间，比如减小年轻代 G1常用参数 -XX:+UseG1GC -XX:MaxGCPauseMillis建议值，G1会尝试调整Young区的块数来达到这个值 -XX:GCPauseIntervalMillis？GC的间隔时间 -XX:+G1HeapRegionSize分区大小，建议逐渐增大该值，1 2 4 8 16 32。随着size增加，垃圾的存活时间更长，GC间隔更长，但每次GC的时间也会更长ZGC做了改进（动态区块大小） G1NewSizePercent新生代最小比例，默认为5% G1MaxNewSizePercent新生代最大比例，默认为60% GCTimeRatioGC时间建议比例，G1会根据这个值调整堆空间 ConcGCThreads线程数量 InitiatingHeapOccupancyPercent启动G1的堆空间占用比例 作业 -XX:MaxTenuringThreshold控制的是什么？A: 对象升入老年代的年龄 B: 老年代触发FGC时的内存垃圾比例 生产环境中，倾向于将最大堆内存和最小堆内存设置为：（为什么？）A: 相同 B：不同 JDK1.8默认的垃圾回收器是：A: ParNew + CMS B: G1 C: PS + ParallelOld D: 以上都不是 什么是响应时间优先？ 什么是吞吐量优先？ ParNew和PS的区别是什么？ ParNew和ParallelOld的区别是什么？（年代不同，算法不同） 长时间计算的场景应该选择：A：停顿时间 B: 吞吐量 大规模电商网站应该选择：A：停顿时间 B: 吞吐量 HotSpot的垃圾收集器最常用有哪些？ 常见的HotSpot垃圾收集器组合有哪些？ JDK1.7 1.8 1.9的默认垃圾回收器是什么？如何查看？ 所谓调优，到底是在调什么？ 如果采用PS + ParrallelOld组合，怎么做才能让系统基本不产生FGC 如果采用ParNew + CMS组合，怎样做才能够让系统基本不产生FGC 1.加大JVM内存 2.加大Young的比例 3.提高Y-O的年龄 4.提高S区比例 5.避免代码内存泄漏 G1是否分代？G1垃圾回收器会产生FGC吗？ 如果G1产生FGC，你应该做什么？ 扩内存 提高CPU性能（回收的快，业务逻辑产生对象的速度固定，垃圾回收越快，内存空间越大） 降低MixedGC触发的阈值，让MixedGC提早发生（默认是45%） 问：生产环境中能够随随便便的dump吗？小堆影响不大，大堆会有服务暂停或卡顿（加live可以缓解），dump前会有FGC 问：常见的OOM问题有哪些？栈 堆 MethodArea 直接内存 如果JVM进程静悄悄退出怎么办？ JVM自身OOM导致 heap dump on oom，这种最容易解决 JVM自身故障 -XX:ErrorFile=/var/log/hs_err_pid.log 超级复杂的文件 包括：crash线程信息 safepoint信息 锁信息 native code cache , 编译事件, gc相关记录 jvm内存映射 等等 被Linux OOM killer杀死 日志位于/var/log/messages egrep -i ‘killed process’ /var/log/messages 硬件或内核问题 dmesg | grep java 找我！ 如何排查直接内存？ NMT打开 – -XX:NativeMemoryTracking=detail perf工具 gperftools 有哪些常用的日志分析工具？ gceasy CPU暴增如何排查？ top -Hp jstack arthas - dashboard thread thread XXXX 两种情况：1：业务线程 2：GC线程 - GC日志 死锁如何排查？ jstack 观察线程情况 arthas - thread -b 参考资料 https://blogs.oracle.com/jonthecollector/our-collectors https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html http://java.sun.com/javase/technologies/hotspot/vmoptions.jsp JVM调优参考文档：https://docs.oracle.com/en/java/javase/13/gctuning/introduction-garbage-collection-tuning.html#GUID-8A443184-7E07-4B71-9777-4F12947C8184 https://www.cnblogs.com/nxlhero/p/11660854.html 在线排查工具 https://www.jianshu.com/p/507f7e0cc3a3 arthas常用命令 Arthas手册： 启动arthas java -jar arthas-boot.jar 绑定java进程 dashboard命令观察系统整体情况 help 查看帮助 help xx 查看具体命令帮助 jmap命令参考： https://www.jianshu.com/p/507f7e0cc3a3 jmap -heap pid jmap -histo pid jmap -clstats pid https://blog.csdn.net/chenssy/article/details/78271744 分析hotspot error file","categories":[],"tags":[]},{"title":"计算机种的二进制","slug":"计算机中的二进制","date":"2020-09-24T00:43:56.373Z","updated":"2020-09-24T08:40:36.094Z","comments":false,"path":"2020/09/24/计算机中的二进制/","link":"","permalink":"http://yoursite.com/2020/09/24/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6/","excerpt":"","text":"计算机中的二进制&nbsp; &nbsp; &nbsp; &nbsp; 之前总结过关于二进制的一些知识点，最近又看到关于二进制的一些知识点，想重新将其总结成博客。 1.关于二进制和十进制的转化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;关于二进制他分为有符号的二进制和无符号的二进制，这两者的区别就是无符号的二进制他的高位（左侧为高位，右侧为低位和十进制的高低位一样）含义就是代表了数字，而有符号的二进制的高位则是代表了符号位，如果是0表示正数，如果是1表示负数。 二进制转为十进制： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上边的例子可以看出我们是如何通过二进制转为十进制的，转化方式就是从右边第一位开始为0次方，依次递增往左，然前边的系数就是当前位置对应的1或者0。 例如：对于110这个二进制数据如果他是有符号的那么最高位1就代表了他是负数，那么转为十进制数据就是-2（-($12^1+02^0$)）前边符号位不要动，后边的10进行二进制转换，如果是无符号的那么转为十进制就是6（$12^2+12^1+0*2^0$）。 十进制转为二进制 &nbsp;&nbsp;&nbsp;&nbsp;十进制转为二进制的主要思路就是用十进制的数据去除以2，然后记录所得到的余数，最后把所得到的余数从左右往左依次排列即可得到对应的二进制。 例如：对于6这个十进制数据，首先用$6/2=3…….0$，然后用得到的商再3去除以2,$3/2=1……1$ ,最后用得到的1再去除以2即$1/2=0……1$ 此时的商是0就不必继续做除法了，然后我们把得到的余数进行从右向左依次排列即110。如果是负数的十进制，也是首先将数字转为二进制然后在最高位（最右边）再去补一位1。 2.关于二进制的原码、补码、反码原码就是最为简单的机器数表示法，用最高位表示符号位，其他位存储该数的二进制的绝对值。如上边提到的110就是一个原码。 原码的特点： 表示直观易懂，与真值转换容易。 源码中的0有两种表示形式，通常的原码的0用+0表示，但是如果在计算中出现了-0则需要硬件将-0变成+0。 原码用来表示加减运算复杂，利用原码对l两数进行加法运算的时候需要判断两数的符号，使得同号相加异号相减。 原码的相反数加上原码不等于0。 反码就是正数的反码还是等于原码；负数的反码就是它的原码除符号位外，按位取反。 例如：我们还是以0110为例，如果这是一个正数那么代表十进制的6，他的反码还是0110，如果是-6，那么他的原码应该是1110此时-6的反码是1001。此时我们来看，-6+6=110+1001=1111，此时得到的这个1111的最高位表示-，他也就是-0的相反数，也就是0。但是如果是-6+(-1)=1001+1110=10111这个10111是-8的反码，也就是意味着负数相加还是有问题的。 反码的特点 在反码中还是用最高位表示符号位，即0正1负。 在反码中0有两种表现形式，也是+0和-0。 反码的表示范围与原码的表示范围一样。 反码解决了一个正数的相反数加这个正数正好等于0的问题，但是面临着另外一个问题，就是两个负数相加存在数据问题。 补码就是正数的补码等于他的原码，负数的补码等于反码+1。 &nbsp;&nbsp;&nbsp;&nbsp;其实负数的补码等于反码+1只是补码的求法，而不是补码的定义，很多人以为求补码就要先求反码，其实并不是，那些计算机学家并不会心血来潮的把反码+1就定义为补码，只不过补码正好就等于反码+1而已。 &nbsp;&nbsp;&nbsp;&nbsp;其实补码的思想是非常巧妙的在《码农翻身》一书中这样推导介绍过补码： &nbsp;&nbsp;&nbsp;&nbsp;在不考虑负数的情况下：如果我们有个4位的二进制数据110这个数据表示的是十进制的6，如果我们把4位全放上1我们可以表示的数是0-15，如果我们想算6-2那么我们可以直接用6+2的补数，此时2的补数就是16-2=14，这样我们可以利用6+14得到这个结果，6+14是个20此时已经发生了溢出即比我们表示的最大数15都已经大了，所以除去溢出的部分我们得到的结果位20-16=4，这样我们得到了最终的结果4。 &nbsp;&nbsp;&nbsp;&nbsp;即便我们利用二进制来进行计算也会得到同样的效果，即0110+1110=10100这是将最高位的1进行溢出得到0100就是我们十进制4。这种思想有点类似与我们的时钟，如果现在是7点我们想让他回到四点此时我们有两种方案，一种是退回到4点，另外一种是前进9格到达4点。这种方式就是数学中的取模操作。那么在无符号的情况下我们该如何计算补码呢，总不能每次按照位数进行减法运算，于是有一种适合计算机的计算补数的方法出来了，就是二进制所有位数取反然后加1（注：这个运算方式只适合无符号的计算。） &nbsp;&nbsp;&nbsp;&nbsp;但是在计算机中我们一般都是有符号的计算，如果在我们考虑负数的情况下：那么最高位就要表示符号位了，此时我们的四位就是可以表示-7到-0以及0-7，此时多了个-0，我们可以将-0当作-8来处理这样就可以表示的数是-8-7，此时我们求补数的逻辑也不应该是之前的那个逻辑了，计算补码应该是我们的符号位保持不变然后数据进行取反加1，如果此时我们来计算6-2那么在二进制中-2的原码应该是1010然后符号位不变得到1101，然后加1得到1110（其实这对应了我们十进制的-6）此时的计算应该是0110+1110=10100高位溢出得到0100即十进制的4。 通过上边的分析我们可以看出我们此后对于相减的操作我们利用加法器就可以实现减法的操作，可以极大简化电路的设计，在计算机内部，我们就是利用了补码来进行二进制表示的，例如java中的Integer.toBinaryString这个ApI就是返回的补码。 3.二进制的位移操作以及或且非 “&gt;&gt;”这个符号是右移操作，右移表示缩小2的N次方 往右移动即所有的二进制位往右移动两位以后高位补0，例如0000 0110&gt;&gt;2右移两位，得到0000 0001。 “&lt;&lt;”这个符号是左移操作，左移则表示放大2的N次方 往左移动就是所有的二进制位往左移动两位低位补0，如0000 0110&lt;&lt;2得到0001 1000。 无符号右移( &gt;&gt;&gt; ) 需要使用其补码进行计算，正数和上边一样操作，负数需要在高位补1。 无符号右移( &lt;&lt;&lt;) 需要使用其补码进行计算，正数的补码等于自己，负数的补码不和负数一样。低位补0。 位与( &amp; ) 第一个操作数的的第n位于第二个操作数的第n位如果都是1，那么结果的第n为也为1，否则为0 位或( | ) 第一个操作数的的第n位于第二个操作数的第n位，只要有一个是1，那么结果的第n为也为1，否则为0 位异或( ^ ) 第一个操作数的的第n位于第二个操作数的第n位相反，那么结果的第n为也为1，否则为0 位非( ~ ) 操作数的第n位为1，那么结果的第n位为0，反之。","categories":[{"name":"计算机组成原理","slug":"计算机组成原理","permalink":"http://yoursite.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"}],"tags":[]},{"title":"mysql的mvcc","slug":"Mysql中的MVCC（多版本并发控制）","date":"2020-09-24T00:43:47.302Z","updated":"2020-09-24T08:41:33.290Z","comments":false,"path":"2020/09/24/Mysql中的MVCC（多版本并发控制）/","link":"","permalink":"http://yoursite.com/2020/09/24/Mysql%E4%B8%AD%E7%9A%84MVCC%EF%BC%88%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%EF%BC%89/","excerpt":"","text":"Mysql中的MVCC（多版本并发控制）Mysql中的MVCC是一个特别难以理解的点，在讲述mvcc之前我们先来简单介绍关于数据库的事务的一点相关知识。 数据库的事务的特性： 原子性：每个事务都是不可分割的最小执行单位。 隔离性：每个事务之间是相互隔离互不影响的。 一致性：在一个事务中的操作要么全部成功要么全部失败。 持久性：一旦事务结束，执行的结果是持久的。 事务的隔离级别： 读未提交：一个事务读取到另外一个事务还没有提交的结果。 读已提交：一个事务只会读到另外一个事务提交的结果。（Oracle默认的隔离级别） 可重复读：在一个事务中第一次读取一个数据的结果和后边读取这个数据的结果是一致的。（mysql默认的隔离级别） 串行化：所有的事务都是串行执行的，不存在并行的情况。 在上边介绍的四种隔离级别中第一种隔离级别很明显是不对的，最后一种很明显是效率底下的，所以在我们的mysql中基本上不会使用第一种和第四种隔离级别，所以我们接下来主要讨论第二种和第三种隔离级别。我们说到这两种隔离级别以后那么这两种隔离级别是如何实现的，在mysql中其实他就是借助于我们的MVCC来实现的这两种隔离级别。MVCC有两个特别重要的概念就是版本链和readview视图。 版本链： ​ 对于使用InnoDB存储引擎的表来说，它的聚簇索引记录中都包含两个必要的隐藏列（row_id并不是必要的，我们 创建的表中有主键或者非NULL唯一键时都不会包含row_id列） trx_id：每次对某条记录进行改动时，都会把对应的事务id赋值给trx_id隐藏列。 roll_pointer：每次对某条记录进行改动时，这个隐藏列会存一个指针，可以通过这个指针找到该记 录修改前的信息。 每个trx_id代表了一个事务，每个rollpointer则指向了当前事务的上一个事务。我们如果有一张user表如图： ​ ​ 图中我们用红色表示已经commit的事务，用绿色表示还没有提交的事务，最开始只有最下边的98号事务并且他是已经提交的，但是当99号事务开始的时候，就会讲roll_pointer指针指向98号事务并且将98号事务的数据放入undo日志中，以方便回滚。此时又来了一个100号事务执行了更新操作，把张三2改为张三3此时100号事务的roll_pointer指向99号事务的数据。同时100号事务没有结束，他又更新了一遍这条数据，此时将张三3改为了张三4，同理他的指针指向了之前的100号事务，此时又来了101号事务对事务进行了更新，指向了之前的100号事务。以上便构成了我们的版本链。 ReadView: ReadView中主要包含4个比较重要的内容： m_ids：表示在生成ReadView时当前系统中活跃的读写事务的事务id列表。 min_trx_id：表示在生成ReadView时当前系统中活跃的读写事务中最小的事务id，也就是m_ids中的最小 值。 max_trx_id：表示生成ReadView时系统中应该分配给下一个事务的id值。 creator_trx_id：表示生成该ReadView的事务的事务id 注意:max_trx_id并不是m_ids中的最大值，事务id是递增分配的。比方说现在有id为1，2，3这三个事务，之后id为3的事务提交了。那么一个新的读事务在生成ReadView时，m_ids就包括1和2，min_trx_id的值就是1， max_trx_id的值就是3,也就是说这个最大事务id是已经创建的事务id中的最大的id而不是活跃的最大id。 版本链访问规则： 当另外一个事务进行第一次查询操作的时候会生成这个readview，我们把上图的事务进行readview的生成m_ids就是[98,99,100,101]其中的min_trx_ids为98，max_trx_ids为101，通过最大的id和最小的id我们可以得到如下图的规则。 image-20200703214900747 这样小于最小id的一定是已经提交的事务，大于最大id的一定是没有开始的事务，在最小以及最大的事务id之间的可能是已经提交过的也有可能是没有提交过的，所以我们就可以通过版本链从上向下遍历得到如下的步骤: 如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同，意味着当前事务在访问它自 己修改过的记录，所以该版本可以被当前事务访问。 如果被访问版本的trx_id属性值小于ReadView中的min_trx_id值，表明生成该版本的事务在当前事 务生成ReadView前已经提交，所以该版本可以被当前事务访问。 如果被访问版本的trx_id属性值大于ReadView中的max_trx_id值，表明生成该版本的事务在当前事 务生成ReadView后才开启，所以该版本不可以被当前事务访问。 如果被访问版本的trx_id属性值在ReadView的min_trx_id和max_trx_id之间，那就需要判断一下 trx_id属性值是不是在m_ids列表中，如果在，说明创建ReadView时生成该版本的事务还是活跃 的，该版本不可以被访问；如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版 本可以被访问 需要注意的是在上图中我们的id是递减的有时候可能因为提交的顺序不一致导致不一定是递减的，如下图： image-20200703220024806 ​ 我们既然说过关于读已提交和可重复读都是利用了版本链那么他们有什么区别呢，其实对于读已提交来说，版本链的生成是每一次查询都会生成一个readview，每次都生成一个readview就是及时的更新已经提交的事务，这样就可以读取到已经提交的事务的数据了。而可重复读则是在第一次查询的时候生成readview,这样不会及时更新，可以重复读取数据。 ​ 我们上边只是针对修改做了简述，还有就是在删除也会使用到MVCC，其实删除可以作为update的特殊情况，删除时会将版本链上的数据复制一份，然后将trx_id修改成删除操作的trx_id，同时在该条记录的头信息（record header）里的（deleted flag）标记位上写上true，来表示当前的记录已经被删除，在查询的时候按照上边的规则，查到对应的记录，如果deleted flag的数据为true意味着已经被删除不返回数据。 MVCC总结： MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用READ COMMITTD、 REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程。可以使不同 事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ这两个隔离级 别的一个很大不同就是：生成ReadView的时机不同，READ COMMITTD在每一次进行普通SELECT操作前都会 生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查 询操作都重复使用这个ReadView就好了。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"HashMap的源码","slug":"HashMap源码解析与理解","date":"2020-06-08T16:00:00.000Z","updated":"2020-09-24T08:42:10.397Z","comments":false,"path":"2020/06/09/HashMap源码解析与理解/","link":"","permalink":"http://yoursite.com/2020/06/09/HashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B8%8E%E7%90%86%E8%A7%A3/","excerpt":"","text":"jdk8中的HashMap源码解析与理解一、预备知识关于hash： ​ 有个非常关键的特点，不定长度的输入固定长度的输出，将一个对象经过一定的hash算法映射成相同长度的hash值。 hash冲突的避免： ​ hash是无法完全避免的，只能通过各种方法手段尽量的减少hash冲突。 关于hash碰撞的解决方案： 开放地址法：假设一个数组有四个长度此时存放了[8,null,10,11,null]两个为null的位置代表没有数据，此时如果有个15来了，15mod 4=3那么这个15应该放在下标为3的位置上，但是3号位置有了数据，所以我们需要用（15+1）mod 4=4此时就放在了4位置，此时恰好没有数据，如果4位置有数据那么我们应该继续向下探测，即（15+1+1）mod 4得到对应的索引位置，直到找到可以放置的位置。 再hash法：再哈希法又叫双哈希法，有多个不同的Hash函数，当发生冲突时，使用第二个，第三个，….，等哈希函数计算地址，直到无冲突。虽然不易发生聚集，但是增加了计算时间。 链地址法：这个就是利用链表来实现，当发生hash冲突的时候我们将冲突的数据继续放在该位置，只不过要形成链表连接在这个位置的元素的后边。我们的hashmap就是利用这种方式来实现的hash冲突的解决。 建立公共溢出区：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表 二、jdk8相对jdk7对于hashmap有哪些改进 jdk8采用了数组+链表+红黑树的数据结构进行数据的存储，而jdk7中采用了数组+链表的处理方式 jdk8中将数据插入链表的时候采用的是尾插法，而jdk7采用的是头插法。 jdk8中新增了一些新的特性，比如hashmap的foreach以及merge和replace方法 jdk8中在扩容数据迁移的时候是采用的高低位链的形式进行，而jdk7则是采用的头尾倒置的方式进行迁移。 三、源码讲解理解jdk8中的hashmap源码中几个重要的参数： ​ 1. 加载因子：在hashmap中这个值默认是0.75。 2. map容量：map的容量并不一定等于实际创建时写入的map的容量，因为hashmap的容量一定是2的n次方，所以当我们申请一个大小为13的map的时候在实际创建的时候会申请一个大小为16的map，也就是说找到第一个大于或者等于申请大小的2的n次方的数据。**但是尤其重要的是这个容量是没有参数的，他一开始是存储在扩容阈值的那个参数中的** 3. 扩容阈值：加载因子*map的容量，假如map的容量为16加载因子为0.75那么扩容的阈值就是 $16\\ast0.75 =12$ ，也就是说当map中存放的元素如果大于了12那么就需要进行扩容。 4. 树化的阈值：在jdk8中当链表的长度大于了8以后会转为红黑树，这个8就是转为红黑树的阈值。 hashmap中的key的hashcode是直接利用hashcode方法生成的吗？ ​ 这个地方不是直接用原生的hashcode方法生成的，而是随原生的hashcode方法进行搞16位异或低16位的扰动，举个例子，假设存放key=“nihao”，如图： image-20200704215356745 我们按照源码中的计算过程如下图： 通过这样得二次位扰动加工处理我们尽可能得避免了hash碰撞得发生，进一步降低hash冲突的几率。 ​ 我们可以通过另外一个例子分析一下是如何降低得，假设我们得数组长度是16那么我们在进行取模运算得时候则是通过hashcode&amp;(16-1)这样得运算得到得索引值，如果我们得key为“abcabcabcabcabc”，我们得到如下: 1954974080（HashCode） 111 0100 1000 0110 1000 1001 1000 0000 2^4-1=15（length-1） 000 0000 0000 0000 0000 0000 0000 1111 &amp;运算 000 0000 0000 0000 0000 0000 0000 0000 而加上高16位异或低16位的“扰动函数”后，结果如下： 原HashCode 1954974080 111 0100 1000 0110 1000 1001 1000 0000 (&gt;&gt;&gt;16)无符号右移16位 29830 000 0000 0000 0000 0111 0100 1000 0110 ^（异或）运算 1955003654 111 0100 1000 0110 1111 1101 0000 0110 2^4-1=15（length-1） 15 000 0000 0000 0000 0000 0000 0000 1111 &amp;（与）运算 6 000 0000 0000 0000 0000 0000 0000 0110 通过上边的例子我们可以得到，如果未进行扰动那么只要hashcode后四位为0那么无论前边28位如何变化得到的结果只会位0，但是进行扰动以后情况有所不同了，显然末尾变成了0110减少了碰撞几率。 hashMap中数组的创建和初始化是一开始进行的吗？ ​ hashmap中的数组不是new的时候创建的，而是在第一次put的时候做的初始化使用懒加载的方式，节省了空间。如图： image-20200705000856653 第一次会走如图的红框部分，进去这个分支以后会执行resize()方法，在resize中会对数组进行初始化。 链表转为红黑树需要什么条件： ​ 链表转为红黑树主要要满足两个条件，一个是链表的长度大于8，另外一个是数组的长度大于64这个我们可以看下源码中的表现： image-20200705001819146 在上图的程序中binCount表示了链表的长度，我们可以看到当bitcount&gt;=7的时候会执行treeifyBin()这个方法，既然是7为什么我们说大于8呢，这是因为bitCount等于7的时候我们其实已经循环了8次因为数组从0开始的，并且我们的p.next = newNode(hash, key, value, null);这段代码先执行也就是说先挂了一个node上去然后去判断的，所以此时除了根节点以外的长度是8而我们加上根节点，长度就变为了9，所以当大于8才会转为执行treeifyBin()这个方法，数组长度大于64又是从哪里体现呢，这个就在treeifyBin()方法中了，如图： 此时我们可以看出当数组的长度小于64的时候会执行resize()操作进行二倍扩容。 为什么转为红黑树的链表长度要大于8？ ​ 因为这是根据一个理论基础叫泊松分布，泊松分布用于描述单位时间（或空间）内随机事件发生的次数。我们可以看到jdk源码中有这么一段注释 1234567891011121314151617181920212223Because TreeNodes are about twice the size of regular nodes, weuse them only when bins contain enough nodes to warrant use(see TREEIFY_THRESHOLD). And when they become too small (due toremoval or resizing) they are converted back to plain bins. Inusages with well-distributed user hashCodes, tree bins arerarely used. Ideally, under random hashCodes, the frequency ofnodes in bins follows a Poisson distribution(http://en.wikipedia.org/wiki/Poisson_distribution) with aparameter of about 0.5 on average for the default resizingthreshold of 0.75, although with a large variance because ofresizing granularity. Ignoring variance, the expectedoccurrences of list size k are (exp(-0.5) * pow(0.5, k) /factorial(k)). The first values are:0: 0.606530661: 0.303265332: 0.075816333: 0.012636064: 0.001579525: 0.000157956: 0.000013167: 0.000000948: 0.00000006more: less than 1 in ten million 通过上面的讲述我们发现其实链表在加载因子位0.75的情况发生树化的概率仅为0.00000006这个概率是极为低下的，也就是说在大多数的情况下我们的链表都不会转为红黑树。 ​ 通常如果 hash 算法正常的话，那么链表的长度也不会很长，那么红黑树也不会带来明显的查询时间上的优势，反而会增加空间负担。所以通常情况下，并没有必要转为红黑树，所以就选择了概率非常小，小于千万分之一概率，也就是长度为 8 的概率，把长度 8 作为转化的默认阈值。 ​ 所以如果平时开发中发现 HashMap 或是 ConcurrentHashMap 内部出现了红黑树的结构，这个时候往往就说明我们的哈希算法出了问题，需要留意是不是我们实现了效果不好的 hashCode 方法，并对此进行改进，以便减少冲突。 为什么要采用链表转为红黑树的方式进行存储？ ​ 为了提高查询的性能，正常情况下如果我们要查询的数据在链表的最后边那么我们需要从前向后的依次进行遍历，直到找到对应元素，这样的话我们的时间复杂度便是o(n),但是我们如果采用了红黑树这种结果的话，他是一种近似平衡二叉树，也就是左节点要比根节点小，右子节点比根节点大，所以此时的查找的时间复杂度位O(logn)。 分析hashmap的put操作流程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //第一次put的时候table为null if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //这个if分支代表当前的这个索引位置的元素为null 其实可以直接放入。 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //如果不为null则需要使用头插法放在链表中 else &#123; Node&lt;K,V&gt; e; K k; //第一个分支意味着新增的key原先就存在，所以直接替换 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //这个分支意味着此时已经是一个红黑树的节点 也就是说链表长度已经大于了8 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //最后分支意味着普通情况的放入 else &#123; for (int binCount = 0; ; ++binCount) &#123; //如果当前的索引位置的节点的下一个节点为null证明可以直接放入到下一个节点 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st //判断转化为红黑树 treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; //这里就是判断是否需要扩容 看的是size是否大于扩容的容量 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 我们通过看源码不难看出put操作首先判断数组是不是null如果是null那么就进行初始化，初始化结束其实就分了四种情况，第一种就是需要放置的索引位置为null可以直接放置数据，第二种情况就是新增的key原先就存在需要直接替换，第三种情况就是他已经树化是一个红黑树，第四种情况就是正常的put操作，进行头插尾插法插入。 注意：jdk1.7的时候是头插法，jdk1.8以后是尾插法插入。 ​ 第一种直接放入元素即可，第二种情况就是判断hash值相同且key值相等，那么就是需要直接替换了，第四种情况就是在我们put的时候我们需要关注是否需要树化，即转为红黑树，我们在上边已经分析过转为红黑树的时机了，在遍历链表的时候同时也判断了是否需要替换相同的key。等到插入完成以后我们来判断是否达到了扩容的标准，即size是否大于threshold这个seize是个全局变量是实际放入到map中的数据量。 hashmap的扩容（resize）解析 ​ 当达到扩容阈值的时候会进行扩容操作，也就是执行resize()方法，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; //旧的数组的长度 第一次put为0 int oldCap = (oldTab == null) ? 0 : oldTab.length; //阈值 int oldThr = threshold; //newThr代表了新的扩容阈值 int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //oldThr*2 这就是真正扩容的大小每次扩容两倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) //如果第一次执行会走入这个方法 newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; //第一次执行会走入这个分支 这里就是加载因子*数组的实际大小 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //如果第一次执行才开始对threshold进行初始化 threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //才开始对数组进行初始化 table = newTab; //这里这个分支意味着不是第一次执行put 因为当是第一次执行put的时候此时oldTab为null if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; //索引位置没有变 if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; ​ 扩容的时候一开始要计算新的map容量以及新的扩容阈值，在计算两者的时候分了两种情况，一种就是数组还没有进行初始化，第二种就是原先已经有数据了，如果没有进行初始化就让新的数组的容量等于扩容阈值， newCap = oldThr为什么会是这样呢，因为这里有个小细节那就是hashmap没有容量这个属性，一开始初始化之前是把容量大小计算以后赋值给了阈值这个字段，初始化第一次以后阈值字段存储的才是真正的阈值即执行了 newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE)。如果进行了初始化那就很明确了就是将原先的容量左移一位同时将阈值字段左移一位。采用位移的方式进行计算是因为乘法运算最终还是会转为位移运算。 ​ 第一步计算扩容后的容量以及阈值以后开始进行数据的迁移工作，即将老数组中的数据迁移到新数组中去。在迁移过程中又分为了四种情况，第一种情况就是当前的索引位置的数据为null这种情况我们可以就不做处理，第二种情况就是当前索引位置只有一个数据，没有形成链表，此时我们直接将这个数据迁移到新的数组的位置就可以了。第三种情况就是迁移的数据已经树化形成了红黑树。第四种情况就是普通没有树化的情况。 ​ 第四种情况是如何扩容的，如果是普通的链表没有树化的情况下是将链表分为了两部分（高位链、低位链），这个关于高位链和低位链我们来分析一下，假如我们一开始的数组大小为16后来扩容成32，并且我们又两个key（key1，key2）如图： 我们发现当我们在利用位运算取模进行索引值计算的时候如果是16我们会与15（1111）进行与运算这样另外的28位的高位无论是什么值都会是0，也就是索引只去取决于低四位。如果是32那么我们会与31（1 1111）进行与运算，此时的高27位无论是什么值都不有影响，我们发现从16到32其实就是多了一位的取决因素，多的这一位恰好就是十进制的16，所以我们不难想到我们将hash值与原有的容量进行与运算即key.hash&amp;10000如果结果为0则意味着key.hash的第五位上是0不会因为扩容被干扰到所以就会放在低位链里边，但是如果不是0那么意味着会被扩容干扰到索引位置，需要放入到高位链中。通过这样区分了高位链和低位链以后我们将低位链放在新数组的原先位置，高位链放在新数组的原索引加上老数组的容量的位置，以此来摒弃了jdk7的倒置的扩容方式，有效的防止了环链的形成。 ​ 第三种情况如果是红黑树的情况下是如何扩容的，我们看下代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125; 我们可以看出其实在已经树化的链表中其实还是有一个链表存在的，这个链表是为了由树退化成链做出的重要操作，所以我们需要维护这个链表，这个链表的维护方式和上边提到的是一样的都是分为高位链和低位链然后进行迁移，迁移完成以后判断对应链表的长度，如果长度小于等于了6就退化成链表，否则继续重新树化链表形成红黑树。 产生的并发问题分析： 因为hashmap线程不安全所以会产生一系列的并发问题，它主要会产生以下的几个问题： get的时候死锁（形成了环链导致的 jdk8有效的避免了这个问题）。 数据丢失问题：如果多个线程同时操作一个槽位那么就会出现数据覆盖丢失的问题。 put非null的数据get为null：具体看jdk7中的transfer方法。","categories":[{"name":"源码解析","slug":"源码解析","permalink":"http://yoursite.com/categories/%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"}],"tags":[]},{"title":"打家劫舍","slug":"三种打家劫舍问题解析","date":"2020-06-08T16:00:00.000Z","updated":"2020-09-24T08:39:18.689Z","comments":false,"path":"2020/06/09/三种打家劫舍问题解析/","link":"","permalink":"http://yoursite.com/2020/06/09/%E4%B8%89%E7%A7%8D%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D%E9%97%AE%E9%A2%98%E8%A7%A3%E6%9E%90/","excerpt":"","text":"三种打家劫舍问题解析在力扣的题库种右这样一种题目，是一种经典的动态规划类题目。 简单版本的打家劫舍 你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。 给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。 示例 1： 输入：[1,2,3,1] 输出：4解释：偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。 偷窃到的最高金额 = 1 + 3 = 4 。 示例 2： 输入：[2,7,9,3,1]输出：12解释：偷窃 1 号房屋 (金额 = 2), 偷窃 3 号房屋 (金额 = 9)，接着偷窃 5 号房屋 (金额 = 1)。 偷窃到的最高金额 = 2 + 9 + 1 = 12 。 提示： 0 &lt;= nums.length &lt;= 100 0 &lt;= nums[i] &lt;= 400 题目解析： ​ 这个问题就很简单了，我们思考满足打家劫舍条件的就是两家不能相连，也就是说当打劫到当前店铺的他不能打劫相邻的上一家店铺，所以我们可以建立两个变量，一个用来存放打劫到当前房屋的时候的最大金额，以及打劫到相邻的上家房屋时候的最大金额，而当前房屋的最大金额又是打劫到上上家房屋时的最大金额加上当前金额，并且我们有一个替换过程，当我们继续往下迭代的时候此一次的n-1家的最大金额就等于当前的最大金额，而下个迭代的n-2家的最大金额就是本迭代的n-1家的最大金额，我们不断的进行替换，迭代下去。 自己在这个问题中存在的疑问： ​ 自己碰到的过不去的点就在于自己本能想到前后都要兼顾不能打劫，意思就是我打劫到当前房屋以后我需要考虑相邻上家不能打劫，相邻下家不能打劫，这就导致了没法继续思考下去，上边的解决方案无疑是比较巧妙的一种解决方式，只考虑打劫到当前房屋时对打劫过来的店铺进行考虑，而不去考虑还未打劫的房屋。 代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123; /** * 解析：这个问题的关键是要建立一种思路，什么思路呢？ * 要这样思考就是要考虑如果打劫这家店铺需要什么条件？ * 打劫这家店铺就不能够打劫它相邻的上一家店铺，有人可能会说 * 他的下一家也不能打劫，但是我们想，当我们打劫到下一家的时候是不是同样的不能打劫上一家 * 接下来要考虑另外一个问题： * 我们打劫到当前店铺以后所获取的钱应该是之前n-2家店铺的获取的钱的最大值加上当前店铺的钱 * 我们不能够直接去考虑到底有多少种打劫方式。那样会极为复杂 */ public int rob(int[] num) &#123; int n_2=0;//前n-2家店的最大钱数 int n_1=0;//第n_1家店的最大钱数 如果我们不打劫当前店铺那么此时最大的钱数就是前n-1家的最大值 for(int i=0;i&lt;num.length;i++)&#123; int temp=n_1; n_1=Math.max(n_2+num[i],n_1);//把前n-2的数据和当前的数据相加 然后与前n-1家的最大值做比较 n_2=temp;//下一次循环的时候n-2就会等于这次的n-1 &#125; return n_1; &#125;&#125; 稍微复杂的打家劫舍问题解析 你是一个专业的小偷，计划偷窃沿街的房屋，每间房内都藏有一定的现金。这个地方所有的房屋都围成一圈，这意味着第一个房屋和最后一个房屋是紧挨着的。同时，相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。 给定一个代表每个房屋存放金额的非负整数数组，计算你在不触动警报装置的情况下，能够偷窃到的最高金额。 示例 1: 输入: [2,3,2]输出: 3解释: 你不能先偷窃 1 号房屋（金额 = 2），然后偷窃 3 号房屋（金额 = 2）, 因为他们是相邻的。示例 2: 输入: [1,2,3,1]输出: 4解释: 你可以先偷窃 1 号房屋（金额 = 1），然后偷窃 3 号房屋（金额 = 3）。 偷窃到的最高金额 = 1 + 3 = 4 。 ​ 和简单版本不同的是这次所有的房屋是围成圈的，有一个思路，如果我们选择了第一个家就不能选择最后一家，如果我们选择了最后一家就不能选择第一家，当然我们可以第一家和最后一家都不选，但是这样我们肯定没有前两种情况打劫的钱多，所以我们只考虑前两种即可，基于前两种情况的考虑我们可以将环形的数组分为两个单向的数组，即索引位0到（n-2）和1到（n-1）然后我们利用普通版的打家劫舍代码分别去计算这两种情况然后取最大值就可以了，所以我们就可以得到我们的代码。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839class Solution &#123; public int rob(int[] nums) &#123; if(nums.length==1)&#123; return nums[0]; &#125; if(nums.length==0)&#123; return 0; &#125; return Math.max(rober(nums,0,nums.length-2),rober(nums,1,nums.length-1)); &#125; public int rober(int[] nums,int start,int end)&#123; //到达上一个最大钱数 int n_1=0; //到达上上个的最大钱数 int n_2=0; for(int i=start;i&lt;=end;i++)&#123; int temp=n_1; n_1= Math.max(n_2+nums[i],n_1); n_2=temp; &#125; return n_1; &#125;&#125; 终极打家劫舍问题 在上次打劫完一条街道之后和一圈房屋后，小偷又发现了一个新的可行窃的地区。这个地区只有一个入口，我们称之为“根”。 除了“根”之外，每栋房子有且只有一个“父“房子与之相连。一番侦察之后，聪明的小偷意识到“这个地方的所有房屋的排列类似于一棵二叉树”。 如果两个直接相连的房子在同一天晚上被打劫，房屋将自动报警。 计算在不触动警报的情况下，小偷一晚能够盗取的最高金额。 示例 1: 输入: [3,2,3,null,3,null,1] 12345 3 / \\2 3 \\ \\ 3 1 输出: 7解释: 小偷一晚能够盗取的最高金额 = 3 + 3 + 1 = 7.示例 2: 输入: [3,4,5,1,3,null,1] 12345 3 / \\ 4 5 / \\ \\ 1 3 1 输出: 9解释: 小偷一晚能够盗取的最高金额 = 4 + 5 = 9. ​ 最后一种打家劫舍问题其实也不难，只不过转化了一下思路而已，之前是相邻两家房屋不能打劫，现在是相同相邻的两层房子不能打劫而已，所以我们的计算方法是一样的只不过是在计算每一层所能够打劫到的钱财时稍许复杂。 代码实现 12345678910/** * Definition for a binary tree node. * public class TreeNode &#123; * int val; * TreeNode left; * TreeNode right; * TreeNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; //建立一个备忘录，用来记录打劫到某个节点的时候的最大钱数，以此来减少重复操作 Map&lt;TreeNode,Integer&gt; map=new HashMap&lt;&gt;(); public int rob(TreeNode root) { if(root==null){return 0;} if(map.containsKey(root)){ return map.get(root); } //n-2层的最大钱数 int n_2=0; //n-1层的最大钱数 int n_1=0; //判断为null的情况 int val=root==null?0:root.val; int temp=n_1; //这一层的加上下下层的最大钱数 n_1=Math.max(val+(root.left==null?0:(rob(root.left.left)+rob(root.left.right))) +(root.right==null?0:(rob(root.right.left)+rob(root.right.right))), rob(root.right)+rob(root.left)); n_2=temp; map.put(root,n_1); return n_1; } } 12​","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"二叉搜索树","slug":"不同的二叉搜索树（96题）","date":"2020-06-08T16:00:00.000Z","updated":"2020-09-24T08:40:58.341Z","comments":false,"path":"2020/06/09/不同的二叉搜索树（96题）/","link":"","permalink":"http://yoursite.com/2020/06/09/%E4%B8%8D%E5%90%8C%E7%9A%84%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%EF%BC%8896%E9%A2%98%EF%BC%89/","excerpt":"","text":"不同的二叉搜索树（96题）给定一个整数 n，求以 1 … n 为节点组成的二叉搜索树有多少种？ 示例: 12345678910输入: 3输出: 5解释:给定 n = 3, 一共有 5 种不同结构的二叉搜索树:1 3 3 2 1 \\ / / / \\ \\ 3 2 1 1 3 2 / / \\ \\2 1 2 3 题解：&nbsp;&nbsp;首先理解题目意思这是一个二叉搜索树，二叉搜索树就是对于一个根节点而言他的左子节点一定比他小，他的右子节点一定比他大。 假如说我们给到的整数是5，那么对于[1,2,3,4,5]这个递增数组来说，如果以3为根节点，那么1，2一定在其左边，4，5一定在其右边。同时每个节点都有作为根节点的可能，其实这时我们可以组成的二叉搜索树的数量就是左边元素可以组成的二叉搜索树的数量x右边元素可以组成的二叉搜索树的数量，这其实是一种笛卡尔积。既然我们要利用动态规划来解决这个问题，那么此时如果我们有n个元素以i元素为根元素，那么我们得到的二叉搜索树的数量就是0-i能够组成的所有的二叉搜索树x(n-i)个元素组成的二叉搜索树的个数。动态转移的方程我们已经得到，那么我么就可以从0开始向后遍历，把从只有0个元素的数组到有n个元素的数组依次计算，然后内层循环遍历每个元素作为根节点的情况。此时我们还需要考虑如果n=0或者n=1我们很容易得到结果，就是1种和1种。那么我们可以定义动态规划的数组dp[n+1]。 我们的计算过程如下： 1234567891011121314151617181920212223242526class Solution &#123; public int numTrees(int n) &#123; //这个动态规划数组的含义就是：dp[i]代表了n==i的时候共有几种二叉搜索树 int[] dp = new int[n+1]; //如果有0个元素那么就是一棵空树也是一种情况 dp[0] = 1; dp[1] = 1; //最外层的循环是用来控制有多少个数字的 //i的值就是有i个元素，通过这样的方式我们可以不断的向后计算直到计算出我们传入的值 for(int i = 2; i &lt; n + 1; i++)&#123; //j是用来控制根节点元素的，在1-j间每个元素都有可能作为根节点 for(int j = 1; j &lt; i + 1; j++)&#123; dp[i] += dp[j-1] * dp[i-j]; &#125; &#125; return dp[n]; &#125;&#125; 动态规划的精髓就是后边我们需要的结果一定时依赖于前边的计算结果的。除此之外他与分治算法非常相似，就是将待求解问题分解成若干个子问题，然后从这些子问题种得到原问题的解。比如上边的问题种，我们需要求n个数据是可以组成的二叉搜索树的个数，那么我们可以分解成左边元素组成的个数乘以右边元素所组成的个数，同时我们不直接计算n个元素而是我们从0个元素往后计算直至推导出我们想要的n个元素的结果。","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"我能赢吗","slug":"力扣464题我能赢吗","date":"2020-06-08T16:00:00.000Z","updated":"2020-09-24T08:40:05.218Z","comments":false,"path":"2020/06/09/力扣464题我能赢吗/","link":"","permalink":"http://yoursite.com/2020/06/09/%E5%8A%9B%E6%89%A3464%E9%A2%98%E6%88%91%E8%83%BD%E8%B5%A2%E5%90%97/","excerpt":"","text":"力扣464题我能赢吗题目描述： 在 “100 game” 这个游戏中，两名玩家轮流选择从 1 到 10 的任意整数，累计整数和，先使得累计整数和达到 100 的玩家，即为胜者。 如果我们将游戏规则改为 “玩家不能重复使用整数” 呢？ 例如，两个玩家可以轮流从公共整数池中抽取从 1 到 15 的整数（不放回），直到累计整数和 &gt;= 100。 给定一个整数 maxChoosableInteger （整数池中可选择的最大数）和另一个整数 desiredTotal（累计和），判断先出手的玩家是否能稳赢（假设两位玩家游戏时都表现最佳）？ 你可以假设 maxChoosableInteger 不会大于 20， desiredTotal 不会大于 300。 示例： 输入： maxChoosableInteger = 10desiredTotal = 11 输出：false 解释：无论第一个玩家选择哪个整数，他都会失败。第一个玩家可以选择从 1 到 10 的整数。如果第一个玩家选择 1，那么第二个玩家只能选择从 2 到 10 的整数。第二个玩家可以通过选择整数 10（那么累积和为 11 &gt;= desiredTotal），从而取得胜利.同样地，第一个玩家选择任意其他整数，第二个玩家都会赢。 题解： 看题目需求是要看看第一个玩家能不能赢，所以我们只需要直到有没有一种情况能够使他获胜就可以了。找到一宗情况就可以返回了，在解题种使用了记忆化回溯的方法（也称之为递归+备忘录），他是动态规划的一种，我们既然是记忆那么记忆的是什么数据，我们需要记忆的是一种情况，假设我们先选择了2然后第二次选择了3这种情况其实和我们第一次先选择了3然后第二次选择2是一样的效果，所以我们需要对其中一种情况进行记录，并将其放入map种每次进来我们先去判断map种存不存在相同的情况，那么我们想我们的key是什么呢，我们可以定义一个数组，这个数组只存放1或者0如果是1则代表了该位置的数据被访问过了，如果是0则表示第一次被访问，通过这个数组我们可以控制数据只被访问一次，同时我们利用这个数组转为字符串作为map的key，value就是能否赢得胜利，上边的选择2,3的两种情况其实都可以用011来作为key。 再来看我们对于递归的解析，假设传入的累计和位10且玩家1选择了1这个数字，那么还剩下2-10这几个数字玩家2选择，也就是我们题目转换成了玩家2从2-10种选择一个数字看是否能够取得胜利，假设当玩家2 选择了2这个数字，那么玩家1就需要从3-10种选择出某个数字来看能够取得胜利，依次类推下去。我们发现可以使用递归的方式来解决这个问题，因为这时除了选择数据的区间不一样其余的都是一样的效果。 我们再来看玩家1赢得胜利的条件是什么，玩家1在选择了某个值后能够赢得胜利的条件就是此时累计和已经达到要求了，或者是对方在剩余的区间选择种输了，可能会有疑问，为什么玩家2输了，玩家1一定会赢呢，因为我们做了判断我们的数组的累计和一定比需要的累计和大，所以这就变成了一个非赢即输的游戏。 代码示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192 public class Solution &#123; /** * 记忆化回溯（也称为递归+备忘录），自顶向下 * 采用记忆化后的时间复杂度为O(2^n)(如果不进行记忆的话，时间复杂度将是O(n!))，可以理解为已经缩成了只有一个分支了 * 然后为什么要进行记忆化： * 因为我们发现，例如[2,3]和[3,2]之后的玩家选择状态都是一样的，都是可以从除了2,3之外的 * 数字进行选择，那么就可以对选择2和3后第一个玩家能不能赢进行记忆存储 * 这里采用state[]数组存储每个数字是否都被选过，选过则记录为1，然后我们将state.toString() * 使得[2,3]和[3,2]它们的结果都是一样的\"0011\"，作为key，存储在HashMap中，value是选了2和3 * 之后第一个玩家是否稳赢 * @param maxChoosableInteger * @param desiredTotal * @return */ public boolean canIWin(int maxChoosableInteger, int desiredTotal) &#123; if (maxChoosableInteger &gt;= desiredTotal) return true; //1,..maxChoosable数列总和都比目标和小 if ((1 + maxChoosableInteger) * maxChoosableInteger / 2 &lt; desiredTotal) return false; //state[1]=1表示1被选了 int[] state = new int[maxChoosableInteger + 1]; return backtraceWitMemo(state, desiredTotal, new HashMap&lt;String, Boolean&gt;()); &#125; private boolean backtraceWitMemo(int[] state, int desiredTotal, HashMap&lt;String, Boolean&gt; map) &#123; //这里比较关键，如何表示这个唯一的状态，例如[2,3]和[3,2]都是\"0011\"，状态一样 String key = Arrays.toString(state); //如果已经记忆了这样下去的输赢结果,记忆是为了防止如[2,3]，[3,2]之后的[1,4,5,..]这个选择区间被重复计算 if (map.containsKey(key)) return map.get(key); for (int i = 1; i &lt; state.length; i++)&#123; if (state[i] == 0)&#123; //如果这个数字i还没有被选中 state[i] = 1; //如果当前选了i已经赢了或者选了i还没赢但是后面对方选择输了 if (desiredTotal - i &lt;= 0 || !backtraceWitMemo(state, desiredTotal - i, map)) &#123; map.put(key, true); //在返回之前回溯 state[i] = 0; return true; &#125; //如果不能赢也要记得回溯 state[i] = 0; &#125; &#125; //如果都赢不了 map.put(key, false); return false; &#125;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"排序算法","slug":"十大排序算法","date":"2020-06-08T16:00:00.000Z","updated":"2020-09-24T08:39:37.195Z","comments":false,"path":"2020/06/09/十大排序算法/","link":"","permalink":"http://yoursite.com/2020/06/09/%E5%8D%81%E5%A4%A7%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","excerpt":"","text":"十大排序算法 简单选择算法 12345678910111213141516171819202122public static void selectSort(int[] arr) &#123; int minINdex = 0; int temp; for (int i = 0; i &lt; arr.length; i++) &#123; for (int j = i + 1; j &lt; arr.length; j++) &#123; if (arr[i] &gt; arr[j]) &#123; minINdex = j; &#125; &#125; //此时不是最小值进行交换 if (minINdex != i) &#123; temp = arr[minINdex]; arr[minINdex] = arr[i]; arr[i] = temp; &#125; &#125; &#125; 简单选择排序算法的思路就是进行嵌套的循环遍历，然后找出最小值，进行外层循环的值的替换。排序比较简单不多详细讲解。 快速排序 12345678910111213141516171819202122232425262728293031323334353637383940414243public static void quickSort(int[] arr, int start, int end) &#123; if (start&gt;=end)&#123; return; &#125; //以第零个元素作为基准数 int stander = arr[start]; int low = start; int high = end; while (low &lt; high) &#123; //如果右边的数组比标准数据大此时不需要交换，只需要将坐标往前移 while (low &lt; high &amp;&amp; stander&lt;= arr[high]) &#123; high--; &#125; //如果没有比标准数据大此时就可以用右边的数据替换左边的数据 arr[low] = arr[high]; //此时经过上边的操作坐标已经移到了数组的左边，所以可以从左边开始遍历了 while (low &lt; high &amp;&amp; arr[low] &lt;= stander) &#123; low++; &#125; //但是如果左边的数据没有比右边的大，此时需要交换 arr[high] = arr[low]; &#125; if (low == high) &#123; //把标准数据赋值给低（高）所在的位置，需要注意的是此时高位和低位已经重合了 arr[low] = stander; //左边的数据和右边的数据分别进行递归调用 quickSort(arr, start, low); //右边的数据进行递归调用 quickSort(arr, low + 1, end); &#125; &#125; 快速排序的过程就是，以最开始的元素位标准，然后当开始元素小于最大元素的时候，就一直循环，如果右边高位的数据比标准数大那么此时就将高位的指针左移，直到找到了标准数据大于了右边的高位的数据，然后将高位的数据换到左边最低位，此时我们应该从左侧开始循环了，然后依然取判断左侧的数据和标准值的关系，只要是小于标准值，那么就让低位的指针右移一位，直到两个高位和低位的指针重合，然后把标准值赋值给重合位置的数据，然后以重合位置位中点将数组分为两个部分，进行递归调用。这里的思路就是以开始坐标为基准将比基准值小的都收集到左侧，比基准值大的都收集到右侧，依次分割递归执行。 直接插入排序 1234567891011121314151617181920212223242526public static void insertSort(int[] arr) &#123; int temp; for (int i = 0; i &lt; arr.length; i++) &#123; //如果当前数字比前一个小才会进行排序 if (arr[i] &lt; arr[i - 1]) &#123; temp = arr[i]; int j; for (j = i - 1; j &gt;= 0; j--) &#123; if (arr[j] &lt;= temp) &#123; break; &#125; &#125; arr[j + 1] = temp; &#125; &#125;&#125; 直接插入排序的思路就是认为前边的数据是排好序的，比如对于[3,6,4,1,9,0]这个数组来说，认为随着遍历前边的数据已经排好序，从一开始遍历第一个元素，然后遍历其后边的元素，如果发现比前边的元素大则不做任何操作，但是如果发现比前边的元素小，那么当前元素就要往前移动，这个移动就是要和前边的所有的元素依次比较。直到找到比自己小的元素，然后中断内层循环，然后进行替换。 希尔排序 123456789101112131415161718public static void shellSort(int[] arr) &#123; //开始的步长为数组长度除以2，每次循环都要除以2 for (int d = arr.length / 2; d &gt; 0; d /= 2) &#123; //遍历所有的元素 for (int i = d; i &lt; arr.length; i++) &#123; //遍历本组的元素 for (int j = i - d; j &gt;= 0; j -= d) &#123; //把本组中大的值交换到后边，小的值交换到前边 if (arr[j] &gt; arr[j + d]) &#123; int temp = arr[j]; arr[j] = arr[j + d]; arr[j + d] = temp; &#125; &#125; &#125; &#125;&#125; 希尔排序其实是属于插入排序，其实对数组进行了分组，比如对于数组[3,6,4,1,9,0],分组开始的步长就是数组的长度除以二，此处得到的d就是我们的步长，其实会发现步长是不断在变短的，我们会将数组分割然后进行两两比较替换。 归并排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445public static void merge(int start, int end, int[] old, int[] temp) &#123; if (start &lt; end) &#123; int midle = (end + start) / 2; merge(start, midle, old, temp); merge(midle + 1, end, old, temp); merageSort(start, end, midle, old, temp); &#125;&#125;public static void merageSort(int start, int end, int midle, int[] old, int[] temp) &#123; int p1 = start; int p2 = end; int p3 = midle + 1; int index = 0; while (p1 &lt; midle &amp;&amp; p3 &lt; p2) &#123; if (old[p1] &lt; old[p3]) &#123; temp[index] = old[p1]; p1++; &#125; else &#123; temp[index] = old[p3]; p3++; &#125; index++; &#125; if (p1 &lt; midle) &#123; for (int i = p1; i &lt; midle; i++) &#123; temp[index] = old[p1]; index++; &#125; &#125; if (p2 &lt; p3) &#123; for (int i = p2; i &lt; p3; i++) &#123; temp[index] = old[p2]; index++; &#125; &#125; for (int j = 0; j &lt; temp.length; j++) &#123; old[start + j] = temp[j]; &#125; &#125; 归并排序其实利用了分治算法的思想分而治之，我们来假设有两个有序数组[1,3]和[2,4]我们如果将这两个数组合并成一个数组并且排序，我们从比较这两个数组的第一个元素发现较小的是1，然后我们将1放入新的数组中，之后就是2然后比较第二个元素我们发现比较小的是3，然后新数组的第三个元素就是3，最后一个元素就是4，就这样我们将这两个数组合并成一个数组并且排序，如果将这种思想利用到我们的数组排序上，那就是将数组不断切割直至分成独立的单个元素我们可以把每一个单个元素看作有序的数组，然后我们搞一个新的数组不断的往新数组中存放数据，但是我们在排序的过程中要判断一个特殊的状态就是分开的两个子数组可能会出现某个数组特别长，导致另外一个数组已经遍历完成了，但是长数组还有数据没有遍历，那么我们可以直接将长数组的元素放在新数组的后边。 冒泡排序 12345678910111213141516171819202122232425262728/** * 冒泡排序 * * @param array */private static void bubbleSort(int[] array) &#123; int temp; for (int i = 0; i &lt; array.length; i++) &#123; for (int j = i + 1; j &lt; array.length; j++) &#123; if (array[i] &gt; array[j]) &#123; temp = array[j]; array[j] = array[i]; array[i] = temp; &#125; &#125; &#125;&#125; 冒泡排序是一种比较简单的排序算法，原理就是我们进行了嵌套循环，我们不断的比较挑出最大的元素往后移动直到数组最后的位置，就像冒泡一样不断向上。 基数排序 1234567891011121314151617181920212223242526272829/** * 基数排序的队列实现 * 基数排序适合于数据位数不一样的数据进行排序 */ public static void baseSortByQueue(int[] arr) &#123; int maxData = arr[0]; for (int i = 1; i &lt; arr.length; i++) &#123; if (maxData &lt; arr[i]) &#123; maxData = arr[i]; &#125; &#125; Queue&lt;Integer&gt;[] myqueue = new LinkedBlockingDeque[9]; int length = (maxData + \"\").length(); for (int j = 0, n = 1; j &lt;= length; j++, n = n * 10) &#123; for (int l = 0; l &lt; arr.length; l++) &#123; int index = arr[l] / n % 10; myqueue[index].offer(arr[l]); &#125; } int index = 0; for (int m = 0; m &lt; myqueue.length; m++) { while (!myqueue[m].isEmpty()) { arr[index] = myqueue[m].poll(); index++; } } } 12345678910111213141516171819202122232425262728293031323334353637383940414243* **桶排序** &#96;&#96;&#96;java public static void bucketSort(int[] arr) &#123; &#x2F;&#x2F;找出数组中的最大元素和最小元素 int min &#x3D; arr[0]; int max &#x3D; arr[0]; for (int i &#x3D; 0; i &lt; arr.length; i++) &#123; max &#x3D; Math.max(max, arr[i]); &#125; &#x2F;&#x2F;计算桶的个数 int length &#x3D; (max - min) &#x2F; arr.length + 1; &#x2F;&#x2F;为了计算简单此处不再使用二维数组，直接采用list嵌套list的形式来进行存储 List&lt;ArrayList&lt;Integer&gt;&gt; arrayLists &#x3D; new ArrayList&lt;&gt;(length); &#x2F;&#x2F;开始构建length个桶 for (int j &#x3D; 0; j &lt; length; j++) &#123; arrayLists.add(new ArrayList&lt;&gt;()); &#125; &#x2F;&#x2F; 将每个元素放入桶 for (int i &#x3D; 0; i &lt; arr.length; i++) &#123; int num &#x3D; (arr[i] - min) &#x2F; (arr.length); arrayLists.get(num).add(arr[i]); &#125; &#x2F;&#x2F; 对每个桶进行排序 for (int i &#x3D; 0; i &lt; arrayLists.size(); i++) &#123; Collections.sort(arrayLists.get(i)); &#125; &#x2F;&#x2F; 将桶中的元素赋值到原序列 int index &#x3D; 0; for (int i &#x3D; 0; i &lt; arrayLists.size(); i++) &#123; for (int j &#x3D; 0; j &lt; arrayLists.get(i).size(); j++) &#123; arr[index++] &#x3D; arrayLists.get(i).get(j); &#125; &#125; &#125; 桶排序的实现思路也比较简单，他是一种以空间换取时间的算法实现，这种排序算法的局限性也是比较大的，它适用于数组元素的最大值和最小值相差不是非常大的情况（也就是所说的数据比较集种的情况），就是用最大元素减去最小元素 计数排序 1234567891011121314151617181920212223242526272829303132333435363738public static void countSort(int[] arr) &#123; //找出数组中的最大元素和最小元素 int min = arr[0]; int max = arr[0]; for (int i = 0; i &lt; arr.length; i++) &#123; if (arr[i] &lt; min) &#123; min = arr[i]; &#125; if (arr[i] &gt; max) &#123; max = arr[i]; &#125; &#125; //得出对应的数组的长度 int d = max - min; //创建统计数组 并计算统计对应元素个数 int[] countArray = new int[d + 1]; for (int j = 0; j &lt; arr.length; j++) &#123; countArray[arr[j] - min]++; &#125; //对统计数组进行变形 后边的元素等于前边的元素之和 int sum = 0; for (int m = 0; m &lt; countArray.length; m++) &#123; sum += countArray[m]; countArray[m] = sum; &#125; //对原始数组倒序 int[] sortArray = new int[arr.length]; for (int i = 0; i &lt;= arr.length - 1; i++) &#123; sortArray[countArray[arr[i] - min] - 1] = arr[i]; countArray[arr[i] - min]--; &#125; System.arraycopy(sortArray, 0, arr, 0, sortArray.length);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283* **堆排序** &#96;&#96;&#96;java &#x2F;** * 堆排序代码实现 * &lt;p&gt; * 顺序存储的二叉树有这么几个特点(通常只考虑完全二叉树)： * &lt;p&gt; * 第n个元素的左子节点为2*n+1 * 第n个元素的右子节点为2*n+2 * 第n个元素的父节点为(n-1)&#x2F;2 *&#x2F; public static void heapSort(int[] arr) &#123; &#x2F;&#x2F;计算开始位置，从最后一层叶子节点的父节点开始遍历 因为是要索引所以-2 int start &#x3D; (arr.length - 2) &#x2F; 2; &#x2F;&#x2F;第一次首先将其调整为大顶堆 for (int i &#x3D; start; i &lt; arr.length - 1; i++) &#123; heapMax(arr, arr.length, i); &#125; for (int i &#x3D; arr.length - 1; i &gt;&#x3D; 0; i--) &#123; int temp &#x3D; arr[i]; arr[i] &#x3D; arr[0]; arr[0] &#x3D; temp; &#x2F;&#x2F;因为第一次操作以后已经构成了大顶堆，所以每次可以从0向后进行调整 heapMax(arr, i, 0); &#125; &#125; &#x2F;** * 找出大顶堆 * &lt;p&gt; * 顺序存储的二叉树有这么几个特点(通常只考虑完全二叉树)： * &lt;p&gt; * 第n个元素的左子节点为2*n+1 * 第n个元素的右子节点为2*n+2 * 第n个元素的父节点为(n-1)&#x2F;2 *&#x2F; public static void heapMax(int[] arr, int size, int index) &#123; if (index &lt; size) &#123; &#x2F;&#x2F;找出左子树和右子树的位置坐标 int leftNode &#x3D; 2 * index + 1; int rightNode &#x3D; 2 * index + 2; &#x2F;&#x2F;一开始默认当前节点为最大值 int max &#x3D; index; if (leftNode &lt; size &amp;&amp; arr[max] &lt; arr[leftNode]) &#123; max &#x3D; leftNode; &#125; if (rightNode &lt; size &amp;&amp; arr[max] &lt; arr[rightNode]) &#123; max &#x3D; rightNode; &#125; if (max !&#x3D; index) &#123; int temp &#x3D; arr[max]; arr[max] &#x3D; arr[index]; arr[index] &#x3D; temp; &#x2F;&#x2F;这次交换可能导致了其子树的结构变化所以需要重新进行排序 heapMax(arr, size, max); &#125; &#125; &#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[]},{"title":"背包九讲","slug":"背包九讲","date":"2020-06-08T16:00:00.000Z","updated":"2020-09-24T08:38:49.652Z","comments":false,"path":"2020/06/09/背包九讲/","link":"","permalink":"http://yoursite.com/2020/06/09/%E8%83%8C%E5%8C%85%E4%B9%9D%E8%AE%B2/","excerpt":"","text":"背包九讲​ 动态规划解题步骤（问题抽象化、建立模型、寻找约束条件、判断是否满足最优性原理、找大问题与小问题的递推关系式、填表、寻找解组成）。 01背包问题 题目：有N件物品和一个容量为V的背包。第i件物品的重量是c[i]，价值是w[i]。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 ​ 利用动态规划解决这个问题，首先就是要找出其中的前后依赖关系，我们要找到状态转移方程，我们需要将问题进行拆解，既然有N件物品且重量为V我们不要直接去考虑这个全部的问题，我们去分析依次将每个物品分别放入1-v重量的背包时候的最大价值。假如我们的物品有三件分重量分别是[1,4,3]价值分别为[1500,3000,2000],背包的容量为4我们可以通过思路建立一个表格，表格的左侧表示的是物品的质量，表格的上方表示的是背包的重量，虽然背包的容量为6，但是我们要去分析，背包质量从1到4的全部最大价值，因为我们在最后求我们需要的值的时候是依赖前边结果的。 1 2 3 4 5 6 1 1500 1500 1500 1500 1500 1500 4 1500 1500 1500 1500 4500 4500 3 1500 1500 1500 3500 4500 4500 ​ 我们来分析下这个表格的含义，当背包的容量为1的时候我们放入第一个物品此时最大价值就是1500，同理当背包容量分别为2，3，4，5，6的时候最大价值也是1500，当我们放入第二个物品的时候如果背包容量为1，我们此时放不进去第二个物品，在此时我们所获得的最大价值其实还是放入第一个物品的时候的最大价值即1500，同理一直到背包容量为4的时候我们都放入不了第二个物品，但是当背包容量为5的时候不一样了，第二个物品可以放入了，因为此时5-1=1我们发现第一个物品可以和第一个物品相容，我们此时获取的最大价值应该是1500+3000=4500所以此时最大的价值就是4500，同样当背包容量为6的时候也是4500的价值，因为6-4=2，虽然得出来此时可以放入第二个物品但是我们的物品不能重复放入，所以当我们分析放入第三个物品的时候同样一直到背包容量为3我们都放入不了第三个物品，到了背包容量为4的时候我们通过计算4-3=1得到此时可以入第一个物品，也就是在容量为4的时候可以放入第一个和第三个物品那么此时的最大重量为1500+2000=3500，3500显然比放入第二个物品时的2500大所以在背包容量为4的时候放入第三个物品的时候的最大价值为3500，由此如果我们创建一个二位数组$dp[i][j]$ 其中的$i$就代表了物品的数量，j代表了背包容量那么我们可以得出状态转移方程式：$dp[i][j]=Math.max(dp[i-1][j],dp[i-c[i]][j]+v[i])$ 其中$i&gt;=c[i]$ 。 通过上边的分析我们可以得出代码试下： 1public class PackageProblem01 &#123; public static void main(String[] args) { //定义三个物品的重量 int[] weight = {1, 4, 3}; //定义三个物品的价值 int[] value = {1500, 3000, 2000}; //定义一共有多少个物品 int n = value.length; //定义背包所能够承载的最大重量 int m = 4; //定义一个二维数组，这个数组用来存放,dp[i][j]代表了当第i个物品放入容量为j的背包中以后的价值， //需要注意的是此时的背包的容量是变化的，因为随着放入背包的物品的增加背包的剩余容量是不断变小的，所以 //通过逆向思维考虑，背包的容量随着物品的增加可以是不断增大的，直到到达了最大的容量 int[][] dp = new int[n + 1][m + 1]; //双层循环，最外层是物品的循环内层是容量的循环 for (int i = 1; i &lt; dp.length; i++) { for (int j = 1; j &lt; dp[0].length; j++) { //此时分为了两种情况，当想要放入物品的重量已经超出了剩余的背包容量，那么此时就直接获取到放置上一个物品的时候的最大价值 //此时上一个物品的最大价值就是在这个物品放入时的最大价值。j此时就代表了重量 i是从1开始的。所以用weight[i-1] if (weight[i - 1] &gt; j) { dp[i][j] = dp[i - 1][j]; } else { //想要存储放入背包的物品需要拆开上边的公式。 if (dp[i - 1][j] &lt; value[i - 1] + dp[i - 1][j - weight[i - 1]]) { //意味着此时需要将当前物品放入背包 dp[i][j] = value[i - 1] + dp[i - 1][j - weight[i - 1]]; } else { dp[i][j] = dp[i - 1][j]; } } } } for (int i = 0; i &lt; dp.length; i++) { System.out.println(Arrays.toString(dp[i])); } } } 123456789101112131415161718192021222324252627282930313233343536优化以后的01背包问题：&#96;&#96;&#96;javapublic class PackageProblem01Upgrage &#123; public static void main(String[] args) &#123; &#x2F;&#x2F;定义三个背包的重量 int[] weight &#x3D; &#123;1, 4, 3&#125;; &#x2F;&#x2F;定义三个背包的价值 int[] value &#x3D; &#123;1500, 3000, 2000&#125;; &#x2F;&#x2F;定义一共有多少个物品 int n &#x3D; value.length; &#x2F;&#x2F;定义背包所能够承载的最大重量 int m &#x3D; 4; int[] dp &#x3D; new int[m + 1]; for (int i &#x3D; 0; i &lt; weight.length; i++) &#123; for (int j &#x3D; m; j &gt;&#x3D;value[i]; j--) &#123; dp[j] &#x3D; Math.max(dp[j], dp[j - weight[i]] + value[i]); &#125; &#125; System.out.println(dp[m]); &#125;&#125; 优化后的代码只是将原先用的二维数组改为了一维数组，降低了空间复杂度，我们对于优化后的代码会产生两个疑问，一就是为什么我们可以改为一维数组，那是因为我们之前的代码中会发现$dp[i][j]$ 只与上一个元素有关系，所以我们完全利用滚动数组，每次数组中的数据都存储上一次的最大值，这样我们就可以用一维数组表示了。第二就是我们改为了一维数组为什么内层循环使用了从后向前遍历的方式，那是因为我们需要对$j&lt;weight[i]$ 的情况进行处理，如果我们从前往后遍历我们后边的数据要依赖于前边的数据，就针对$weight[1]$ 来说，在正向遍历的过程中$dp[i]$ 是不断赋值的，这样如果使用动态转移方程式我们如果最终找到$j-weight[i]$ 的值它是被改变了的，他已经不是0了所以我们使用$dp[j - weight[i]] + value[i]$ 就会造成数据偏大的问题。倒序遍历就是为了保证前边的值不变还是上一伦的数据，因为我们依赖$j-weight[i]$ 而这个值在这一轮中不可以变才行，所以此时只有从后往前遍历才会解决这个问题。 完全背包问题 题目：有N种物品和一个容量为V的背包，每种物品都有无限件可用。第$i$种物品的费用是$c[i]$，价值是$w[i]$。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 ​ 完全背包问题的最大特点就是物品可以重复使用，其实完全背包问题可以转化为01背包问题来求解，完全背包的物品可以重复利用那么我么其实可以以01背包为基础，只不过每次再遍历的时候我们加一层分析就是关于放入同一个物品数量的分析，可以通过加一层循环的方式解决，就是计算出当放入一个时的最大价值，放入两个时的最大价值，直到放入的物品的质量超过总质量为止，这就是完全背包的思路了，此时完全背包的状态转移方程为$dp[i][j]=Math.max(dp[i-1][j],dp[i-kc[i]][j]+kv[i])$ 。 代码实现如下： 1234567891011121314151617public class PackageProblemComplete &#123; public static void main(String[] args) &#123; //定义三个背包的重量 int[] weight = &#123;1, 4, 3, 5&#125;; //定义三个背包的价值 int[] value = &#123;1500, 3000, 2000, 5000&#125;; //定义一共有多少个物品 int n = value.length; //定义背包所能够承载的最大重量 int m = 10; int[][] dp = new int[n + 1][m + 1]; //完全背包问题无非就是商品可以重复选择，此时需要在原来的基础上进行多一次的循环，就是对于选择的商品数量进行循环 for (int i = 1; i &lt; dp.length; i++) { for (int j = 1; j &lt; dp[0].length; j++) { for (int k = 0; k * weight[i-1] &lt; j; k++) { dp[i][j] = Math.max(dp[i - 1][j], value[i-1] + dp[i - 1][j - k * weight[i - 1]]); } } } for (int i = 0; i &lt; dp.length; i++) { System.out.println(Arrays.toString(dp[i])); } } } 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 ​3. **多重背包问题** 题目： 有N种物品和一个容量为V的背包。第$i$种物品最多有$n[i]$件可用，每件费用是$c[i]$，价值是$w[i]$。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 ​ 多重背包也没有什么难度，其实就是完全背包的变种，之前沃我们限制物品的数量k，使得$k * weight[i-1] &lt; j$ 我们想要实现多重背包只需要将这个公式改一下就可以了，即$k&lt;n[i]$ 原有的逻辑不变这样就可以解决多重背包问题。 &#96;&#96;&#96;java public class PackageProblemMultiple &#123; public static void main(String[] args) &#123; &#x2F;&#x2F;定义三个物品的重量 int[] weight &#x3D; &#123;1, 4, 3, 5&#125;; &#x2F;&#x2F;定义三个物品的价值 int[] value &#x3D; &#123;1500, 3000, 2000, 5000&#125;; &#x2F;&#x2F;定义三种物品的最大数量 int[] num&#x3D;&#123;2,4,1,4&#125;; &#x2F;&#x2F;定义一共有多少个物品 int n &#x3D; value.length; &#x2F;&#x2F;定义背包所能够承载的最大重量 int m &#x3D; 10; int[][] dp &#x3D; new int[n + 1][m + 1]; &#x2F;&#x2F;完全背包问题无非就是商品可以重复选择，此时需要在原来的基础上进行多一次的循环，就是对于选择的商品数量进行循环 for (int i &#x3D; 1; i &lt; dp.length; i++) &#123; for (int j &#x3D; 1; j &lt; dp[0].length; j++) &#123; for (int k &#x3D; 0; k &lt;num[i-1]&amp;&amp;j&gt;k * weight[i - 1]; k++) &#123; dp[i][j] &#x3D; Math.max(dp[i - 1][j], value[i-1] + dp[i - 1][j - k * weight[i - 1]]); &#125; &#125; &#125; for (int i &#x3D; 0; i &lt; dp.length; i++) &#123; System.out.println(Arrays.toString(dp[i])); &#125; &#125; &#125; ​ 三种背包混合背包问题 问题：如果将P01、P02、P03混合起来。也就是说，有的物品只可以取一次（01背包），有的物品可以取无限次（完全背包），有的物品可以取的次数有一个上限（多重背包）。应该怎么求解呢？ ​ 混合背包也没啥，其实就是在原先的基础上多了一个每个物品可用的最大次数的数组，然后当我们每次去进行最内层循环的时候我们的k值进行控制最大值不能够超过我们对应的物品的最大数量就可以了。同时判断的时候分为两种情况一种是01背包和多重背包，另外一种是完全背包，我们的背包数量的数组0就代表了这种物品可以放无限次，也就是因为这这是一种完全背包。 代码示例如下： 1public class PackageProblemMixed &#123; public static void main(String[] args) { //定义三个物品的重量 int[] weight = {1, 4, 3, 5}; //定义三个物品的价值 int[] value = {1500, 3000, 2000, 5000}; //定义三种物品的最大数量 0代表无限次数 int[] num = {2, 4,0,5}; //定义一共有多少个物品 int n = value.length; //定义背包所能够承载的最大重量 int m = 10; int[][] dp = new int[n + 1][m + 1]; //完全背包问题无非就是商品可以重复选择，此时需要在原来的基础上进行多一次的循环，就是对于选择的商品数量进行循环 for (int i = 1; i &lt; dp.length; i++) { for (int j = 1; j &lt; dp[0].length; j++) { if (num[i-1] != 0) { for (int k = 0; k &lt;num[i-1]&amp;&amp;j&gt;k * weight[i - 1]; k++) { dp[i][j] = Math.max(dp[i - 1][j], value[i-1] + dp[i - 1][j - k * weight[i - 1]]); } }else { for (int k = 0; k * weight[i-1] &lt; j; k++) { dp[i][j] = Math.max(dp[i - 1][j], value[i - 1] + dp[i - 1][j - k * weight[i - 1]]); } } } } for (int i = 0; i &lt; dp.length; i++) { System.out.println(Arrays.toString(dp[i])); } } } 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859 ​5. **二维费用的背包问题** 问题： 二维费用的背包问题是指：对于每件物品，具有两种不同的费用；选择这件物品必须同时付出这两种代价；对于每种代价都有一个可付出的最大值（背包容量）。问怎样选择物品可以得到最大的价值。设这两种代价分别为代价1和代价2，第$i$件物品所需的两种代价分别为$a[i]和b[i]$。两种代价可付出的最大值（两种背包容量）分别为V和U。物品的价值为$w[i]$。 ​ 在原先的背包问题中咱们只限制了总的重量不可以超过背包的总重量，二维费用的问题只不过是在原先的基础上加了一层限制而已。 代码示例： &#96;&#96;&#96;java public class PackageProblemTwoDimensional &#123; public static void main(String[] args) &#123; &#x2F;&#x2F;定义三个背包的重量 int[] weight &#x3D; &#123;1, 4, 3&#125;; &#x2F;&#x2F;第二维的重量限制 int[] weight2 &#x3D; &#123;2, 4, 6&#125;; &#x2F;&#x2F;定义三个背包的价值 int[] value &#x3D; &#123;1500, 3000, 2000&#125;; &#x2F;&#x2F;定义背包所能够承载的最大重量 int m &#x3D; 4; &#x2F;&#x2F;第二维的重量限制 int m2 &#x3D; 8; int[][] dp &#x3D; new int[m + 1][m2 + 1]; for (int i &#x3D; 1; i &lt;weight.length; i++) &#123; for (int j &#x3D; m; j &gt;&#x3D; weight[i - 1]; j--) &#123; for (int k &#x3D; m2; k &gt;&#x3D; weight2[i - 1]; k--) &#123; dp[j][k] &#x3D; Math.max(dp[j][k], dp[j - weight[i - 1]][k - weight2[i - 1]] + value[i - 1]); &#125; &#125; &#125; for (int i &#x3D; 0; i &lt; dp.length; i++) &#123; System.out.println(Arrays.toString(dp[i])); &#125; &#125; &#125; 分组背包问题 问题：有N件物品和一个容量为V的背包。第$i$件物品的费用是$c[i]$，价值是$w[i]$。这些物品被划分为若干组，每组中的物品互相冲突，最多选一件。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 ​ 分组背包问题就是01背包+完全背包的高级进阶，因为你需要从各个组中选择出数据，然后组内的数据互斥，不能选两边，但是组可以选两次，对于每组的商品我们有几种选择呢，如果这个组内有n个商品那么一共有n+1种选择，不选择也算是一种选择，所以是n+1种选择。我们此时的最外层循环应该是分组的数量，第二层循环应该是背包的重量，最内层循环应该是每组的商品的重量。 代码示例如下： 1234567891011121314151617181920212223242526272829import java.util.Scanner;public class Bag4 &#123; public static void main(String[] args) &#123; Scanner sc=new Scanner(System.in); int n=sc.nextInt(); int m=sc.nextInt(); int[][] f=new int[n+2][m+2]; for (int i = 1; i &lt;=n ; i++) &#123; int num=sc.nextInt(); for (int j = 0; j &lt;num ; j++) &#123; int v=sc.nextInt(); int w=sc.nextInt(); for (int k = m; k&gt;=v; k--) &#123; f[i][k]=Math.max(f[i][k],f[i-1][k-v]+w); &#125;/*f[i][k]还没有被遍历到，为0.k《v的时候f[i][k]都为0 如果使用f[i][k]=Math.max(f[i-1][k],f[i-1][k-v]+w)，则会出现取值问题。 例如(f[i-1][k]大于f[i-1][k-v]+w)时 f[i][k]=f[i-1][k]，但在前面num的循环中f[i][k]已经大于f[i-1][k] 此时 f[i][k]应该等于之前的f[i-1][k-v]+w，而不是f[i-1][k]*/ &#125; for (int k = m; k&gt;=0; k--)//需要遍历到0 &#123; f[i][k]=Math.max(f[i][k],f[i-1][k]); &#125;//保证 f[i][k]最大值，应该可以优化，将j的循环放入到k中 &#125; System.out.println(f[n][m]); &#125;&#125; 背包问题求方案数 简化的问题：这种背包问题的物品间存在某种“依赖”的关系。也就是说，$i$依赖于$j$，表示若选物品$i$，则必须选物品$j$。为了简化起见，我们先设没有某个物品既依赖于别的物品，又被别的物品所依赖；另外，没有某件物品同时依赖多件物品。 求背包问题的方案 一般而言，背包问题是要求一个最优值，如果要求输出这个最优值的方案，可以参照一般动态规划问题输出方案的方法：记录下每个状态的最优值是由状态转移方程的哪一项推出来的，换句话说，记录下它是由哪一个策略推出来的。便可根据这条策略找到上一个状态，从上一个状态接着向前推即可。 ​ 思路就是加了一个二维数组用来存储方案，我们来借用01背包问题来做个代码示例。 代码示例如下： 1public class PackageProblem01 &#123; public static void main(String[] args) { //定义三个物品的重量 int[] weight = {1, 4, 3}; //定义三个物品的价值 int[] value = {1500, 3000, 2000}; //定义一共有多少个物品 int n = value.length; //定义背包所能够承载的最大重量 int m = 4; //定义一个二维数组用来存放放入物品的顺序 int[][] path = new int[n + 1][m + 1]; int[][] dp = new int[n + 1][m + 1]; //双层循环，最外层是物品的循环内层是容量的循环 for (int i = 1; i &lt; dp.length; i++) { for (int j = 1; j &lt; dp[0].length; j++) { if (weight[i - 1] &gt; j) { dp[i][j] = dp[i - 1][j]; } else { if (dp[i - 1][j] &lt; value[i - 1] + dp[i - 1][j - weight[i - 1]]) { path[i][j] = 1; dp[i][j] = value[i - 1] + dp[i - 1][j - weight[i - 1]]; } else { dp[i][j] = dp[i - 1][j]; } } } } //最后来遍历一下放入背包的物品 此时需要倒序遍历 int i = path.length - 1; int j = path[0].length - 1; while (i &gt; 0 &amp;&amp; j &gt; 0) { if (path[i][j] == 1) { //意味着放入了背包 System.out.println(i + &quot;放入背包&quot;); j = j - weight[i - 1]; } i--; } } } 有依赖的背包问题 来源牛客网： 王强今天很开心，公司发给N元的年终奖。王强决定把年终奖用于购物，他把想买的物品分为两类：主件与附件，附件是从属于某个主件的，下表就是一些主件与附件的例子： 主件 附件 电脑 打印机，扫描仪 书柜 图书 书桌 台灯，文具 工作椅 无 如果要买归类为附件的物品，必须先买该附件所属的主件。每个主件可以有 0 个、 1 个或 2 个附件。附件不再有从属于自己的附件。王强想买的东西很多，为了不超出预算，他把每件物品规定了一个重要度，分为 5 等：用整数 1 ~ 5 表示，第 5 等最重要。他还从因特网上查到了每件物品的价格（都是 10 元的整数倍）。他希望在不超过 N 元（可以等于 N 元）的前提下，使每件物品的价格与重要度的乘积的总和最大。 设第 j 件物品的价格为 v[j] ，重要度为 w[j] ，共选中了 k 件物品，编号依次为 j 1 ， j 2 ，……， j k ，则所求的总和为： v[j 1 ]*w[j 1 ]+v[j 2 ]*w[j 2 ]+ … +v[j k ]*w[j k ] 。（其中 * 为乘号） 请你帮助王强设计一个满足要求的购物单。 输入描述: 1234567输入的第 1 行，为两个正整数，用一个空格隔开：N m（其中 N （ &lt;32000 ）表示总钱数， m （ &lt;60 ）为希望购买物品的个数。）从第 2 行到第 m+1 行，第 j 行给出了编号为 j-1 的物品的基本数据，每行有 3 个非负整数 v p q（其中 v 表示该物品的价格（ v&lt;10000 ）， p 表示该物品的重要度（ 1 ~ 5 ）， q 表示该物品是主件还是附件。如果 q&#x3D;0 ，表示该物品为主件，如果 q&gt;0 ，表示该物品为附件， q 是所属主件的编号） 输出描述: 1输出文件只有一个正整数，为不超过总钱数的物品的价格与重要度乘积的总和的最大值（ &lt;200000 ）。 示例1 输入 1234561000 5800 2 0400 5 1300 5 1400 3 0500 2 0 输出 12200 ​ ​ 一个“主件”和它的附件集合，实际上是一个物品组，每一个选择某个“主件”或者“主件+附件”的策略，实际上相当于这个物品组中的一个物品，其费用和价值，都是策略中的物品的值的总和。这样的话，对于该简化描述的依赖背包问题的，可以转化为分组背包问题，参考分组背包问题的解决思路，可以解决该问题。 代码示例如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import java.util.Scanner;public class PackageProblemRely &#123; public static void main(String[] args) &#123; Scanner scanner = new Scanner(System.in); // 总钱数 int N = scanner.nextInt(); // 购买物品个数 int m = scanner.nextInt(); int[] f = new int[N + 1]; // 分组，goods[i][0]为主件，goods[i][1]为附件1，goods[i][2]为附件2 Good[][] goods1 = new Good[60][4]; for (int i = 1; i &lt;= m; i++) &#123; int v = scanner.nextInt(); int p = scanner.nextInt(); int q = scanner.nextInt(); Good t = new Good(v, v * p); if (q == 0) &#123; goods1[i][0] = t; &#125; else &#123; if (goods1[q][1] == null) &#123; goods1[q][1] = t; &#125; else &#123; goods1[q][2] = t; &#125; &#125; &#125; for (int i = 1; i &lt;= m; i++) &#123; for (int j = N; j &gt;= 0 &amp;&amp; goods1[i][0] != null; j--) &#123; //以下代码从分组中选择价值最大的。共五种情况：不选主件，选主件，选附件1和主件，选附件2和主件，选附件1和附件2和主件 Good master = goods1[i][0]; int max = f[j]; if (j &gt;= master.v) &#123; max=Math.max(max,f[j - master.v] + master.vp); &#125; //如果附件1不为null int vt; if (goods1[i][1] != null) &#123; if (j &gt;= (vt = master.v + goods1[i][1].v) )&#123; max = Math.max(max,f[j - vt] + master.vp + goods1[i][1].vp); &#125; &#125; //如果附件2不为null if (goods1[i][2] != null) &#123; if (j &gt;= (vt = master.v + goods1[i][1].v + goods1[i][2].v)) &#123; max = Math.max(max,f[j - vt] + master.vp + goods1[i][1].vp + goods1[i][2].vp); &#125; &#125; f[j] = max; &#125; &#125; System.out.println(f[N]); &#125;&#125;class Good &#123; int v; int vp; public Good(int v, int vp) &#123; this.v = v; this.vp = vp; &#125;&#125;","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[]}]}